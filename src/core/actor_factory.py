"""åŸºäº LangChain å·¥å…·çš„åŠ¨æ€æ™ºèƒ½ä½“å·¥å‚ã€‚"""

import inspect
import json
import logging
import os
import uuid
from datetime import datetime
from typing import TYPE_CHECKING, Any, Union


if TYPE_CHECKING:
    from .dynamic_actor import DynamicActor

import requests
from langchain_core.tools import StructuredTool, Tool
from pydantic import BaseModel, Field

from src.tools.file_tools import _find_project_root

from ..llm.base import BaseLLMClient
from ..tools.web_tools import BraveSearchTool


logger = logging.getLogger(__name__)


class TaskSpecification(BaseModel):
    """ç”¨äºåˆ›å»ºæ™ºèƒ½ä½“çš„ä»»åŠ¡è§„æ ¼ã€‚"""

    task_id: str = Field(..., description="ä»»åŠ¡å”¯ä¸€æ ‡è¯†")
    description: str = Field(..., description="ä»»åŠ¡æè¿°")
    parent_goal: str | None = Field(None, description="çˆ¶çº§ç›®æ ‡")
    context: dict[str, Any] = Field(default_factory=dict, description="æ‰§è¡Œä¸Šä¸‹æ–‡")
    constraints: list[str] = Field(default_factory=list, description="çº¦æŸæ¡ä»¶")
    priority: str = Field(default="medium", description="ä¼˜å…ˆçº§")
    estimated_duration: int | None = Field(None, description="é¢„ä¼°æ—¶é•¿(åˆ†é’Ÿ)")


class TaskAnalysis(BaseModel):
    """LLM å¯¹ä»»åŠ¡éœ€æ±‚åˆ†æçš„ç»“æœã€‚"""

    task_type: str = Field(..., description="ä»»åŠ¡ç±»å‹")
    domain: str = Field(..., description="é¢†åŸŸ")
    required_capabilities: list[str] = Field(..., description="æ‰€éœ€èƒ½åŠ›")
    complexity: str = Field(..., description="å¤æ‚åº¦")
    key_challenges: list[str] = Field(..., description="å…³é”®æŒ‘æˆ˜")
    recommended_tools: list[str] = Field(..., description="æ¨èå·¥å…·åŒ…")
    knowledge_areas: list[str] = Field(..., description="çŸ¥è¯†é¢†åŸŸ")


class ActorConfiguration(BaseModel):
    """æ™ºèƒ½ä½“é…ç½®ã€‚"""

    actor_id: str = Field(..., description="æ™ºèƒ½ä½“ID")
    task_id: str = Field(..., description="å…³è”ä»»åŠ¡ID")
    persona: str = Field(..., description="äººæ ¼è®¾å®š")
    tools: list[str] = Field(..., description="å·¥å…·åç§°åˆ—è¡¨")
    knowledge: str = Field(..., description="æ³¨å…¥çš„çŸ¥è¯†")
    system_prompt: str = Field(..., description="å®Œæ•´ç³»ç»Ÿæç¤º")
    execution_config: dict[str, Any] = Field(default_factory=dict, description="æ‰§è¡Œé…ç½®")
    metadata: dict[str, Any] = Field(default_factory=dict, description="å…ƒæ•°æ®")


class ActorFactory:
    """æŒ‰éœ€åˆ›å»ºå…·å¤‡åŠ¨æ€é…ç½®çš„ä¸“ç”¨æ™ºèƒ½ä½“çš„å·¥å‚ã€‚"""

    def __init__(self, llm_client: BaseLLMClient, initialize_tools: bool = True):
        self.llm = llm_client
        # å·¥å…·ä½¿ç”¨ç»Ÿè®¡å’Œå»ºè®®è®°å½•
        self.tool_usage_stats = {}
        self.tool_recommendations_history = []

        if initialize_tools:
            self._initialize_tool_bundles()
        else:
            # æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨ç©ºçš„å·¥å…·åŒ…
            self.tool_bundles = {
                "web_research": {"tools": []},
                "file_operations": {"tools": []},
                "weather_services": {"tools": []},
                "data_processing": {"tools": []},
                "travel_services": {"tools": []},
                "research_integration": {"tools": []},
            }

    def _initialize_tool_bundles(self):
        """åˆå§‹åŒ–å·¥å…·åŒ…ã€‚"""

        # ç½‘ç»œæœç´¢å·¥å…· - ä¼˜å…ˆä½¿ç”¨ Brave Searchï¼Œå›é€€åˆ° Tavily
        web_search_tools = []

        # å°è¯•åˆå§‹åŒ– Brave Search
        brave_api_key = os.getenv("BRAVE_SEARCH_API_KEY")
        if brave_api_key:
            try:
                brave_search_tool = BraveSearchTool(api_key=brave_api_key, max_results=5)

                # åˆ›å»º LangChain å·¥å…·åŒ…è£…å™¨
                def brave_search_func(query: str) -> str:
                    """ä½¿ç”¨ Brave Search è¿›è¡Œç½‘ç»œæœç´¢ï¼Œè¿”å›æ›´è¯¦ç»†çš„ç»“æœç”¨äºæ·±åº¦ç ”ç©¶ã€‚"""
                    try:
                        result = brave_search_tool.execute_sync(query)
                        return brave_search_tool.format_results(result, max_length=3000)
                    except Exception as e:
                        return f"Brave æœç´¢å¤±è´¥: {e!s}"

                brave_search_langchain = Tool(
                    name="brave_search",
                    func=brave_search_func,
                    description="ä½¿ç”¨ Brave Search API è¿›è¡Œç½‘ç»œæœç´¢ï¼Œè¿”å›æ ¼å¼åŒ–çš„æœç´¢ç»“æœ",
                )
                web_search_tools.append(brave_search_langchain)

            except Exception as e:
                print(f"è­¦å‘Š: Brave Search åˆå§‹åŒ–å¤±è´¥: {e!s}")

        # æš‚æ—¶æ³¨é‡Šæ‰ Tavily Searchï¼Œä¼˜å…ˆä½¿ç”¨ Brave Search
        # tavily_api_key = os.getenv("TAVILY_API_KEY")
        # if tavily_api_key:
        #     try:
        #         tavily_search = TavilySearch(
        #             tavily_api_key=tavily_api_key,
        #             max_results=3,
        #             search_depth="advanced",
        #             include_answer=True,
        #             include_raw_content=True,
        #         )
        #         web_search_tools.append(tavily_search)
        #     except Exception as e:
        #         print(f"è­¦å‘Š: Tavily Search åˆå§‹åŒ–å¤±è´¥: {str(e)}")

        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„æœç´¢å·¥å…·ï¼Œåªæ˜¯è­¦å‘Š
        if not web_search_tools:
            print("è­¦å‘Š: æœªè®¾ç½® BRAVE_SEARCH_API_KEYï¼Œç½‘ç»œæœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨")

        # ç»Ÿä¸€çš„ docs åŸºå‡†ç›®å½•ï¼ˆç”¨äºæ–‡ä»¶ç›¸å…³å·¥å…·çš„ç›¸å¯¹è·¯å¾„è§£æï¼‰
        # ä½¿ç”¨ session éš”ç¦»ï¼šæ¯ä¸ª session çš„æ–‡ä»¶ä¿å­˜åœ¨ç‹¬ç«‹ç›®å½•ä¸­
        project_root = _find_project_root()

        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æš‚æ—¶ä½¿ç”¨ docs/ ä½œä¸ºåŸºå‡†ï¼Œå®é™…çš„ session_id ä¼šåœ¨ Agent åˆ›å»ºæ—¶åŠ¨æ€ä¼ é€’
        # ä½†ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å…ˆä¿æŒç°æœ‰é€»è¾‘ï¼Œå› ä¸ºä¿®æ”¹éœ€è¦ä¼ é€’ session_id åˆ°è¿™é‡Œ
        docs_base_dir = os.path.join(project_root, "docs")
        os.makedirs(docs_base_dir, exist_ok=True)

        def _resolve_in_docs(path: str) -> str:
            """Resolve relative paths under the project's docs directory.

            Absolute paths are returned unchanged. Empty or "." paths resolve
            to the docs base directory.
            """
            if not path or path == ".":
                return docs_base_dir
            if os.path.isabs(path):
                return path
            return os.path.join(docs_base_dir, path)

        # æ–‡ä»¶æ“ä½œå·¥å…·ï¼ˆé»˜è®¤ç›¸å¯¹è·¯å¾„å‡è§£æåˆ° docs/ ä¸‹ï¼‰
        def read_file_func(file_path: str) -> str:
            """è¯»å–æ–‡ä»¶å†…å®¹ã€‚"""
            try:
                file_path = _resolve_in_docs(file_path)
                with open(file_path, encoding="utf-8") as f:
                    return f.read()
            except FileNotFoundError:
                # æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼Œè¿”å›ç‰¹æ®Šæ ‡è®°ï¼Œè®©æ™ºèƒ½ä½“çŸ¥é“éœ€è¦ç­‰å¾…
                return "FILE_NOT_FOUND: æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¨åé‡è¯•"
            except Exception as e:
                return f"è¯»å–æ–‡ä»¶å¤±è´¥: {e!s}"

        class ReadFilesInput(BaseModel):
            file_paths: list[str] = Field(
                ...,
                description="è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨",
            )

        def read_files_func(file_paths: list[str]) -> str:
            """æ‰¹é‡è¯»å–å¤šä¸ªæ–‡ä»¶å¹¶è¿”å›å†…å®¹æ˜ å°„ã€‚"""
            if not isinstance(file_paths, list) or not file_paths:
                return "è¯»å–å¤±è´¥ï¼šè¯·æä¾›éç©ºçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨"

            results: dict[str, str] = {}
            errors: dict[str, str] = {}

            for path in file_paths:
                resolved = _resolve_in_docs(path)
                try:
                    with open(resolved, encoding="utf-8") as f:
                        results[path] = f.read()
                except Exception as exc:
                    errors[path] = str(exc)

            payload = {
                "results": results,
                "errors": errors,
            }

            return json.dumps(payload, ensure_ascii=False)

        def write_file_func(file_path: str, content: str) -> str:
            """
            å†™å…¥æ–‡ä»¶å†…å®¹åˆ° docs/ ç›®å½•ã€‚

            **è·¯å¾„è§„åˆ™**ï¼š
            - ç›¸å¯¹è·¯å¾„ä¼šè‡ªåŠ¨è§£æåˆ° docs/ ç›®å½•ä¸‹
            - ä¾‹å¦‚ï¼šå†™ "report.md" â†’ å®é™…ä¿å­˜åˆ° "docs/report.md"
            - ä¾‹å¦‚ï¼šå†™ "task_123/report.md" â†’ å®é™…ä¿å­˜åˆ° "docs/task_123/report.md"
            - âš ï¸ ä¸è¦åœ¨è·¯å¾„å‰åŠ  "docs/"ï¼Œå¦åˆ™ä¼šå˜æˆ "docs/docs/"
            """
            try:
                file_path = _resolve_in_docs(file_path)
                dir_path = os.path.dirname(file_path)
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(content)
                return f"æˆåŠŸå†™å…¥æ–‡ä»¶: {file_path}"
            except Exception as e:
                return f"å†™å…¥æ–‡ä»¶å¤±è´¥: {e!s}"

        class WriteFilesInput(BaseModel):
            files: dict[str, str] = Field(
                ...,
                description="é”®ä¸ºæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼Œä¼šè‡ªåŠ¨å†™å…¥ docs/ï¼‰ï¼Œå€¼ä¸ºè¦å†™å…¥çš„å†…å®¹",
            )

        def write_files_func(files: dict[str, str]) -> str:
            """æ‰¹é‡å†™å…¥å¤šä¸ªæ–‡ä»¶ã€‚"""
            if not isinstance(files, dict) or not files:
                return "å†™å…¥å¤±è´¥ï¼šè¯·æä¾›è‡³å°‘ä¸€ä¸ªæ–‡ä»¶"

            successes: list[str] = []
            errors: dict[str, str] = {}

            for path, content in files.items():
                resolved = _resolve_in_docs(path)
                try:
                    directory = os.path.dirname(resolved)
                    if directory and not os.path.exists(directory):
                        os.makedirs(directory, exist_ok=True)
                    with open(resolved, "w", encoding="utf-8") as f:
                        f.write(content)
                    successes.append(path)
                except Exception as exc:
                    errors[path] = str(exc)

            payload = {
                "written": successes,
                "errors": errors,
            }

            return json.dumps(payload, ensure_ascii=False)

        class WriteFileInput(BaseModel):
            file_path: str = Field(
                ...,
                description="ç›®æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„ï¼Œä¼šè‡ªåŠ¨ä¿å­˜åˆ° docs/ ç›®å½•ä¸‹ï¼Œä¸è¦åŠ  docs/ å‰ç¼€ï¼‰",
            )
            content: str = Field(..., description="è¦å†™å…¥çš„æ–‡æœ¬å†…å®¹")

        def list_directory_func(directory_path: str) -> str:
            """åˆ—å‡ºç›®å½•å†…å®¹ï¼ˆç›¸å¯¹è·¯å¾„è§£æåˆ° docs/ï¼‰ã€‚"""
            try:
                directory_path = _resolve_in_docs(directory_path)
                if not os.path.exists(directory_path):
                    return f"ç›®å½•ä¸å­˜åœ¨: {directory_path}"
                if not os.path.isdir(directory_path):
                    return f"è·¯å¾„ä¸æ˜¯ç›®å½•: {directory_path}"
                items = sorted([e for e in os.listdir(directory_path)])
                return f"ç›®å½• {directory_path} å†…å®¹:\n" + "\n".join(items)
            except Exception as e:
                return f"åˆ—å‡ºç›®å½•å¤±è´¥: {e!s}"

        # å¤©æ°”æŸ¥è¯¢å·¥å…·
        def get_weather_func(city: str) -> str:
            """è·å–æŒ‡å®šåŸå¸‚çš„å½“å‰å¤©æ°”ä¿¡æ¯ã€‚"""
            # ä½¿ç”¨ WeatherAPI çš„ API æ¥è·å–å¤©æ°”ä¿¡æ¯
            api_key = os.getenv("WEATHER_API_KEY")
            if not api_key:
                return "é”™è¯¯ï¼šæœªè®¾ç½® WEATHER_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®"

            base_url = "http://api.weatherapi.com/v1/current.json"
            params = {
                "key": api_key,
                "q": city,
                "aqi": "no",  # ä¸éœ€è¦ç©ºæ°”è´¨é‡æ•°æ®
            }

            try:
                # è°ƒç”¨å¤©æ°” API
                response = requests.get(base_url, params=params, timeout=10)

                if response.status_code == 200:
                    data = response.json()
                    # æ‹¿åˆ°å¤©æ°”å’Œæ¸©åº¦
                    weather = data["current"]["condition"]["text"]
                    temperature = data["current"]["temp_c"]
                    humidity = data["current"]["humidity"]
                    wind_kph = data["current"]["wind_kph"]
                    return f"åŸå¸‚ {city} å½“å‰å¤©æ°”ï¼š{weather}ï¼Œæ¸©åº¦ {temperature}Â°Cï¼Œæ¹¿åº¦ {humidity}%ï¼Œé£é€Ÿ {wind_kph} km/h"
                else:
                    return f"æ— æ³•æ£€ç´¢ {city} çš„å¤©æ°”ä¿¡æ¯ï¼ŒAPIè¿”å›çŠ¶æ€ç : {response.status_code}"

            except requests.exceptions.RequestException as e:
                return f"è·å– {city} å¤©æ°”ä¿¡æ¯æ—¶ç½‘ç»œè¯·æ±‚å¤±è´¥: {e!s}"
            except Exception as e:
                return f"è·å– {city} å¤©æ°”ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e!s}"

        # è´§å¸è½¬æ¢ï¼ˆExchangeRate-APIï¼‰
        def currency_convert_func(from_currency: str, to_currency: str, amount: float) -> str:
            """ä½¿ç”¨ ExchangeRate-API å°†é‡‘é¢ä»ä¸€ç§è´§å¸è½¬æ¢ä¸ºå¦ä¸€ç§è´§å¸ã€‚"""
            api_key = os.getenv("EXCHANGE_RATE_API_KEY")
            if not api_key:
                return "é”™è¯¯ï¼šæœªè®¾ç½® EXCHANGE_RATE_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env é…ç½®ã€‚"

            base_url = f"https://v6.exchangerate-api.com/v6/{api_key}/pair/{from_currency.upper()}/{to_currency.upper()}/{amount}"
            try:
                resp = requests.get(base_url, timeout=10)
                resp.raise_for_status()
                data = resp.json()
                if data.get("result") == "success":
                    rate = data.get("conversion_rate")
                    converted = data.get("conversion_result")
                    return f"{amount} {from_currency.upper()} -> {converted} {to_currency.upper()} (rate: {rate})"
                else:
                    return f"è´§å¸è½¬æ¢å¤±è´¥ï¼š{data.get('error-type') or data}"
            except requests.RequestException as e:
                return f"è´§å¸è½¬æ¢ç½‘ç»œé”™è¯¯ï¼š{e!s}"
            except Exception as e:
                return f"è´§å¸è½¬æ¢å‘ç”Ÿé”™è¯¯ï¼š{e!s}"

        class CurrencyConvertInput(BaseModel):
            from_currency: str = Field(..., description="æºè´§å¸ä»£ç ï¼Œå¦‚ CNY")
            to_currency: str = Field(..., description="ç›®æ ‡è´§å¸ä»£ç ï¼Œå¦‚ JPY")
            amount: float = Field(..., description="é‡‘é¢")

        # æ—¶åŒºæŸ¥è¯¢ï¼ˆTimeZoneDBï¼‰
        def get_timezone_func(
            zone: str | None = None, lat: float | None = None, lng: float | None = None
        ) -> str:
            """æŸ¥è¯¢æ—¶åŒºä¿¡æ¯ï¼Œæ”¯æŒæŒ‰ IANA åŒºåŸŸåæˆ–ç»çº¬åº¦ã€‚"""
            api_key = os.getenv("TIMEZONEDB_API_KEY")
            if not api_key:
                return "é”™è¯¯ï¼šæœªè®¾ç½® TIMEZONEDB_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env é…ç½®ã€‚"

            if zone:
                params = {
                    "key": api_key,
                    "format": "json",
                    "by": "zone",
                    "zone": zone,
                }
            elif lat is not None and lng is not None:
                params = {
                    "key": api_key,
                    "format": "json",
                    "by": "position",
                    "lat": lat,
                    "lng": lng,
                }
            else:
                return "é”™è¯¯ï¼šè¯·æä¾› zone æˆ– (lat, lng)ã€‚"

            try:
                resp = requests.get(
                    "https://api.timezonedb.com/v2.1/get-time-zone", params=params, timeout=10
                )
                resp.raise_for_status()
                data = resp.json()
                if data.get("status") == "OK":
                    zone_name = data.get("zoneName")
                    gmt_offset = data.get("gmtOffset")
                    abbrev = data.get("abbreviation")
                    local_time = data.get("formatted") or data.get("timestamp")
                    return f"æ—¶åŒº: {zone_name}, åç§»: {gmt_offset}, ç®€å†™: {abbrev}, æœ¬åœ°æ—¶é—´: {local_time}"
                return f"æ—¶åŒºæŸ¥è¯¢å¤±è´¥ï¼š{data.get('message') or data}"
            except requests.RequestException as e:
                return f"æ—¶åŒºæŸ¥è¯¢ç½‘ç»œé”™è¯¯ï¼š{e!s}"
            except Exception as e:
                return f"æ—¶åŒºæŸ¥è¯¢å‘ç”Ÿé”™è¯¯ï¼š{e!s}"

        class TimezoneInput(BaseModel):
            zone: str | None = Field(None, description="IANA åŒºåŸŸåï¼Œå¦‚ Asia/Tokyo")
            lat: float | None = Field(None, description="çº¬åº¦ï¼Œä¸ lng è”åˆä½¿ç”¨")
            lng: float | None = Field(None, description="ç»åº¦ï¼Œä¸ lat è”åˆä½¿ç”¨")

        # å…¬å…±å‡æœŸï¼ˆNager.Dateï¼‰
        def get_public_holidays_func(country_code: str, year: int) -> str:
            """æŸ¥è¯¢æŒ‡å®šå›½å®¶ä¸å¹´ä»½çš„å…¬å…±å‡æœŸï¼ˆNager.Dateï¼‰ã€‚"""
            base_url = os.getenv("NAGER_DATE_BASE_URL", "https://date.nager.at")
            url = f"{base_url}/api/v3/PublicHolidays/{year}/{country_code.upper()}"
            try:
                resp = requests.get(url, timeout=10)
                resp.raise_for_status()
                data = resp.json()
                if not isinstance(data, list):
                    return f"è¿”å›æ ¼å¼å¼‚å¸¸ï¼š{data}"
                # ç®€è¦æ±‡æ€»
                items = [
                    f"{item.get('date')} - {item.get('localName')} ({item.get('name')})"
                    for item in data[:10]
                ]
                more = "" if len(data) <= 10 else f"ï¼Œå…¶ä½™ {len(data) - 10} æ¡çœç•¥"
                return "å…¬å…±å‡æœŸï¼š\n" + "\n".join(items) + more
            except requests.RequestException as e:
                return f"å…¬å…±å‡æœŸæŸ¥è¯¢ç½‘ç»œé”™è¯¯ï¼š{e!s}"
            except Exception as e:
                return f"å…¬å…±å‡æœŸæŸ¥è¯¢å‘ç”Ÿé”™è¯¯ï¼š{e!s}"

        class PublicHolidaysInput(BaseModel):
            country_code: str = Field(..., description="å›½å®¶ä»£ç ï¼Œå¦‚ JP/CN")
            year: int = Field(..., description="å¹´ä»½ï¼Œå¦‚ 2025")

        # æ•°æ®å¤„ç†å·¥å…·
        def parse_json_func(json_string: str) -> str:
            """è§£æ JSON å­—ç¬¦ä¸²ã€‚"""
            try:
                parsed = json.loads(json_string)
                return f"JSONè§£ææˆåŠŸ: {json.dumps(parsed, ensure_ascii=False, indent=2)}"
            except Exception as e:
                return f"JSONè§£æå¤±è´¥: {e!s}"

        # ç ”ç©¶æ•´åˆå·¥å…·
        # å®šä¹‰å·¥å…·åŒ…
        self.tool_bundles = {
            "web_research": {
                "tools": web_search_tools,
                "description": "é€šè¿‡ Brave Search æˆ– Tavily æœç´¢ç½‘ç»œå¹¶è¿”å›ç»“æ„åŒ–æ‘˜è¦",
                "use_cases": ["å®æ—¶ä¿¡æ¯æœç´¢", "èƒŒæ™¯è°ƒç ”", "äº‹å®éªŒè¯", "èµ„æ–™æ”¶é›†"],
            },
            "file_operations": {
                "tools": [
                    Tool(
                        name="read_file",
                        func=read_file_func,
                        description="è¯»å–æŒ‡å®šè·¯å¾„çš„æ–‡ä»¶å†…å®¹",
                    ),
                    StructuredTool.from_function(
                        name="read_files",
                        func=read_files_func,
                        args_schema=ReadFilesInput,
                        description="æ‰¹é‡è¯»å–å¤šä¸ªæ–‡ä»¶ï¼Œè¿”å›å†…å®¹å’Œé”™è¯¯ä¿¡æ¯çš„ JSON ç»“æ„",
                    ),
                    StructuredTool.from_function(
                        name="write_file",
                        func=write_file_func,
                        args_schema=WriteFileInput,
                        description="å°†å†…å®¹å†™å…¥æŒ‡å®šè·¯å¾„çš„æ–‡ä»¶",
                    ),
                    StructuredTool.from_function(
                        name="write_files",
                        func=write_files_func,
                        args_schema=WriteFilesInput,
                        description="æ‰¹é‡å†™å…¥å¤šä¸ªæ–‡ä»¶ï¼Œä¸€æ¬¡å®Œæˆå¤šä»½å†…å®¹çš„ä¿å­˜",
                    ),
                    Tool(
                        name="list_directory",
                        func=list_directory_func,
                        description="åˆ—å‡ºæŒ‡å®šç›®å½•çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•",
                    ),
                ],
                "description": "åœ¨å·¥ä½œç›®å½•å†…è¯»å–/å†™å…¥æ–‡ä»¶å¹¶ç®¡ç†ç›®å½•",
                "use_cases": ["æŸ¥çœ‹/ä¿å­˜æ–‡æ¡£", "ç”ŸæˆæŠ¥å‘Š", "æ•´ç†å·¥ä½œåŒº", "è¾…åŠ©ä»£ç /ç¬”è®°ç¼–è¾‘"],
            },
            "weather_services": {
                "tools": [
                    Tool(
                        name="get_weather",
                        func=get_weather_func,
                        description="è·å–æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ¸©åº¦ã€æ¹¿åº¦ã€é£é€Ÿç­‰",
                    )
                ],
                "description": "ä½¿ç”¨ WeatherAPI æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”",
                "use_cases": ["æ´»åŠ¨è§„åˆ’", "è¡Œç¨‹å¤‡å¿˜", "ç®€å•æ°”å€™åˆ†æ"],
            },
            "data_processing": {
                "tools": [
                    Tool(
                        name="parse_json",
                        func=parse_json_func,
                        description="è§£æå’Œæ ¼å¼åŒ–JSONæ ¼å¼çš„å­—ç¬¦ä¸²æ•°æ®",
                    )
                ],
                "description": "è§£æ JSON å­—ç¬¦ä¸²å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ",
                "use_cases": ["è§£æ API å“åº”", "æ•°æ®æ¸…æ´—", "å¿«é€Ÿæ ¼å¼æ ¡éªŒ"],
            },
            "travel_services": {
                "tools": [
                    StructuredTool.from_function(
                        name="currency_convert",
                        func=currency_convert_func,
                        args_schema=CurrencyConvertInput,
                        description="è´§å¸è½¬æ¢ï¼šfrom_currency, to_currency, amountã€‚ä¼˜å…ˆä½¿ç”¨æ­¤å·¥å…·è¿›è¡Œæ±‡ç‡æ¢ç®—ï¼Œé¿å…é€šè¿‡ç½‘ç»œæœç´¢è·å–æ±‡ç‡æ•°æ®ã€‚",
                    ),
                    StructuredTool.from_function(
                        name="get_timezone",
                        func=get_timezone_func,
                        args_schema=TimezoneInput,
                        description="æŸ¥è¯¢æ—¶åŒºï¼šæä¾› zone æˆ– (lat,lng)",
                    ),
                    StructuredTool.from_function(
                        name="get_public_holidays",
                        func=get_public_holidays_func,
                        args_schema=PublicHolidaysInput,
                        description="æŸ¥è¯¢å…¬å…±å‡æœŸï¼šcountry_code, year",
                    ),
                ],
                "description": "é€šç”¨è¾…åŠ©ï¼šæ±‡ç‡æ¢ç®—ã€æ—¶åŒºç¡®è®¤ã€èŠ‚å‡æ—¥æŸ¥è¯¢",
                "use_cases": ["è¡Œç¨‹åˆ¶å®š", "è·¨å›½ä¼šè®®å®‰æ’", "é¢„ç®—æ¢ç®—", "èŠ‚å‡æ—¥æé†’"],
            },
            "research_integration": {
                "tools": [
                    StructuredTool.from_function(
                        func=self._create_research_integration_func(),
                        name="integrate_research",
                        description="æ™ºèƒ½å‘ç°å’Œæ•´åˆä»»åŠ¡ç›®å½•ä¸‹çš„æ‰€æœ‰ç ”ç©¶æ–‡ä»¶ï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Šã€‚ç”¨äºæœ€ç»ˆæŠ¥å‘Šç”Ÿæˆä»»åŠ¡ã€‚",
                    )
                ],
                "description": "ç ”ç©¶æ•´åˆï¼šè‡ªåŠ¨å‘ç°ã€åˆ†æå’Œæ•´åˆå­ä»»åŠ¡çš„ç ”ç©¶æˆæœ",
                "use_cases": ["æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ", "ç ”ç©¶æ•°æ®æ•´åˆ", "å¤šæºä¿¡æ¯æ±‡æ€»"],
            },
        }

    def _create_research_integration_func(self):
        """åˆ›å»ºç ”ç©¶æ•´åˆå·¥å…·å‡½æ•°ã€‚"""
        from ..tools.research_integration_tool import ResearchIntegrationTool

        def integrate_research_func(
            task_directory: str, output_file: str, original_goal: str = ""
        ) -> str:
            """æ™ºèƒ½å‘ç°å’Œæ•´åˆä»»åŠ¡ç›®å½•ä¸‹çš„æ‰€æœ‰ç ”ç©¶æ–‡ä»¶ï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Šã€‚"""
            tool = ResearchIntegrationTool()
            return tool.execute_sync(
                task_directory=task_directory,
                output_file=output_file,
                original_goal=original_goal,
                llm_client=self.llm,
            )

        return integrate_research_func

    async def create_agent(self, task_spec: TaskSpecification) -> "DynamicActor":
        """
        åˆ›å»ºé’ˆå¯¹ç‰¹å®šä»»åŠ¡éœ€æ±‚å®šåˆ¶çš„æ™ºèƒ½ä½“ã€‚

        Args:
            task_spec: åŒ…å«éœ€æ±‚ä¸ä¸Šä¸‹æ–‡çš„ä»»åŠ¡è§„æ ¼

        Returns:
            é…ç½®å®Œæ•´çš„ DynamicActor å®ä¾‹
        """
        try:
            # æ£€æµ‹æ˜¯å¦ä¸ºæ±‡æ€»ä»»åŠ¡
            if (
                task_spec.task_id == "task_final_summary"
                or task_spec.context.get("task_type") == "summary"
            ):
                return await self._create_summary_agent(task_spec)

            # ğŸš€ ä¼˜åŒ–ï¼šåˆå¹¶ LLM è°ƒç”¨ - ä¸€æ¬¡æ€§è·å–æ‰€æœ‰é…ç½®ä¿¡æ¯
            # åŸå…ˆ: 3æ¬¡ç‹¬ç«‹è°ƒç”¨ï¼ˆåˆ†æã€çŸ¥è¯†ã€äººæ ¼ï¼‰
            # ç°åœ¨: 1æ¬¡ç»¼åˆè°ƒç”¨ï¼ŒèŠ‚çœ 66% çš„è°ƒç”¨æ¬¡æ•°
            agent_design = await self._design_complete_agent(task_spec)

            task_analysis = agent_design["task_analysis"]
            persona = agent_design["persona"]
            knowledge = agent_design["knowledge"]

            # 2. é€‰æ‹©å·¥å…·åŒ…ï¼ˆLangChain Toolsï¼‰
            selected_tools = self._select_tool_bundles(task_analysis)

            # 3. è½¬æ¢ä¸º Function Calling æ ¼å¼
            functions = self._tools_to_functions(selected_tools)

            # 6. ç»„è£…ç³»ç»Ÿæç¤ºï¼ˆä¼ é€’ session_id ç”¨äºæ–‡ä»¶éš”ç¦»è§„èŒƒï¼‰
            session_id = task_spec.context.get("session_id")
            system_prompt = self._compose_prompt_for_functions(
                persona=persona,
                knowledge=knowledge,
                environment=self._get_environment(),
                selected_tools=selected_tools,
                session_id=session_id,
            )

            # 7. è®°å½•å·¥å…·æ¨èï¼ˆå·¥å…·é—­ç¯ï¼‰
            planner_suggested_tools = task_spec.context.get("required_tools", [])
            self.record_tool_recommendation(
                task_id=task_spec.task_id,
                recommended_tools=task_analysis.recommended_tools,
                planner_suggested=planner_suggested_tools,
            )

            # 8. æ„å»ºé…ç½®
            config = ActorConfiguration(
                actor_id=f"actor_{uuid.uuid4().hex[:8]}",
                task_id=task_spec.task_id,
                persona=persona,
                tools=[tool.name for tool in selected_tools],
                knowledge=knowledge,
                system_prompt=system_prompt,
                execution_config=self._build_execution_config(task_analysis),
                metadata={
                    "created_at": datetime.now().isoformat(),
                    "task_analysis": task_analysis.dict(),
                    "selected_bundles": task_analysis.recommended_tools,
                    "planner_suggested": planner_suggested_tools,
                },
            )

            # 8. åˆ›å»º DynamicActor å®ä¾‹
            from .dynamic_actor import DynamicActor

            return DynamicActor(
                actor_id=config.actor_id,
                task_id=config.task_id,
                task_description=task_spec.description,
                llm_client=self.llm,
                tools=selected_tools,
                functions=functions,
                system_prompt=config.system_prompt,
                config=config,
            )

        except Exception as e:
            # é™çº§ç­–ç•¥ï¼šåˆ›å»ºåŸºç¡€é…ç½®
            return self._create_fallback_agent(task_spec, str(e))

    async def _design_complete_agent(self, task_spec: TaskSpecification) -> dict:
        """
        ä¸€æ¬¡æ€§è®¾è®¡å®Œæ•´çš„æ™ºèƒ½ä½“é…ç½®ï¼ˆåˆå¹¶çš„ LLM è°ƒç”¨ï¼‰ã€‚

        åŸå…ˆéœ€è¦ 3 æ¬¡ LLM è°ƒç”¨ï¼š
        1. _analyze_task_requirements - åˆ†æä»»åŠ¡
        2. _retrieve_knowledge - ç”ŸæˆçŸ¥è¯†
        3. _generate_persona - ç”Ÿæˆäººæ ¼

        ç°åœ¨åˆå¹¶ä¸º 1 æ¬¡è°ƒç”¨ï¼Œè®© LLM åœ¨å®Œæ•´ä¸Šä¸‹æ–‡ä¸­ç»¼åˆæ€è€ƒï¼Œ
        æ›´æ™ºèƒ½ä¸”èŠ‚çœæˆæœ¬ã€‚
        """

        comprehensive_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“è®¾è®¡ä¸“å®¶ï¼Œè´Ÿè´£ä¸ºç‰¹å®šä»»åŠ¡è®¾è®¡æœ€ä¼˜çš„ AI æ™ºèƒ½ä½“é…ç½®ã€‚

## ä»»åŠ¡ä¿¡æ¯
- ä»»åŠ¡æè¿°ï¼š{task_spec.description}
- çˆ¶çº§ç›®æ ‡ï¼š{task_spec.parent_goal or "æ— "}
- å·²çŸ¥çº¦æŸï¼š{", ".join(task_spec.constraints) if task_spec.constraints else "æ— "}
- æ‰§è¡Œä¸Šä¸‹æ–‡ï¼š{json.dumps(task_spec.context, ensure_ascii=False)}

## å¯ç”¨å·¥å…·èƒ½åŠ›
- web_research: ç½‘ç»œæœç´¢(Brave/Tavily)ã€ç½‘é¡µå†…å®¹æå–ã€ä¿¡æ¯æ”¶é›†
- file_operations: æ–‡ä»¶è¯»å†™ã€ç›®å½•åˆ—è¡¨ã€æ–‡æ¡£ç®¡ç†
- data_processing: JSONè§£æã€æ•°æ®è½¬æ¢ã€ç»“æ„åŒ–å¤„ç†
- weather_services: å®æ—¶å¤©æ°”æŸ¥è¯¢ã€æ°”è±¡ä¿¡æ¯
- travel_services: è´§å¸è½¬æ¢ã€æ—¶åŒºæŸ¥è¯¢ã€èŠ‚å‡æ—¥ä¿¡æ¯ï¼ˆæ¶‰åŠè´§å¸ä¼˜å…ˆæ¨èï¼‰
- code_execution: Pythonä»£ç æ‰§è¡Œã€è„šæœ¬è¿è¡Œã€è®¡ç®—ä»»åŠ¡
- research_integration: æ™ºèƒ½æ•´åˆç ”ç©¶æ–‡ä»¶ã€ç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼ˆæœ€ç»ˆæŠ¥å‘Šä»»åŠ¡å¿…é¡»æ¨èï¼‰

## ä½ çš„ä»»åŠ¡
è¯·ç»¼åˆåˆ†æå¹¶è¿”å›å®Œæ•´çš„æ™ºèƒ½ä½“è®¾è®¡æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

1. **ä»»åŠ¡åˆ†æ**ï¼š
   - ä»»åŠ¡ç±»å‹å’Œé¢†åŸŸ
   - æ‰€éœ€èƒ½åŠ›å’Œå·¥å…·
   - å¤æ‚åº¦è¯„ä¼°
   - å…³é”®æŒ‘æˆ˜

2. **äººæ ¼è®¾å®š**ï¼š
   - è®¾è®¡ä¸“ä¸šã€å‹å¥½ã€æœ‰å¸®åŠ©çš„è§’è‰²ï¼ˆ50å­—ä»¥å†…ï¼‰
   - è¦ä½“ç°è¯¥ä»»åŠ¡çš„ä¸“ä¸šæ€§

3. **çŸ¥è¯†æ³¨å…¥**ï¼š
   - å…³é”®æ¦‚å¿µå’ŒåŸåˆ™ï¼ˆ100å­—ä»¥å†…ï¼‰
   - æœ€ä½³å®è·µå»ºè®®ï¼ˆ100å­—ä»¥å†…ï¼‰
   - å¸¸è§é™·é˜±æé†’ï¼ˆ100å­—ä»¥å†…ï¼‰

## è¿”å›æ ¼å¼ï¼ˆJSONï¼‰
{{
    "task_analysis": {{
        "task_type": "research|analysis|creation|communication",
        "domain": "general|coding|data|business|education",
        "required_capabilities": ["web_search", "file_write"],
        "complexity": "low|medium|high",
        "key_challenges": ["æ—¶é—´é™åˆ¶", "ä¿¡æ¯ä¸è¶³"],
        "recommended_tools": ["web_research", "file_operations"],
        "knowledge_areas": ["ç›¸å…³ä¸“ä¸šé¢†åŸŸ"]
    }},
    "persona": "æ‚¨å¥½ï¼æˆ‘æ˜¯ä¸“ä¸šçš„...åŠ©æ‰‹ï¼Œæ“…é•¿...",
    "knowledge": "å…³é”®æ¦‚å¿µï¼š...\\næœ€ä½³å®è·µï¼š...\\næ³¨æ„äº‹é¡¹ï¼š..."
}}

**é‡è¦**ï¼š
- æ¶‰åŠè´§å¸/æ±‡ç‡æ—¶ï¼Œrecommended_tools å¿…é¡»åŒ…å« travel_services
- æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆä»»åŠ¡ï¼ˆåŒ…å«"æœ€ç»ˆæŠ¥å‘Š"ã€"æ±‡æ€»"ã€"æ•´åˆ"ç­‰å…³é”®è¯ï¼‰ï¼Œrecommended_tools å¿…é¡»åŒ…å« research_integration
"""

        try:
            # ä½¿ç”¨ä¸“é—¨çš„JSONæ¨¡å¼è°ƒç”¨LLM
            response = await self.llm.complete_chat_json(
                [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»»åŠ¡åˆ†æåŠ©æ‰‹ï¼Œå¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼å“åº”ã€‚",
                    },
                    {"role": "user", "content": comprehensive_prompt},
                ]
            )

            # éªŒè¯å“åº”ç»“æ„
            if not isinstance(response, dict):
                raise ValueError("LLM response is not a dictionary")

            if "task_analysis" not in response:
                raise ValueError("Missing task_analysis in response")

            # è½¬æ¢ task_analysis ä¸º TaskAnalysis å¯¹è±¡
            analysis_data = response["task_analysis"]
            task_analysis = TaskAnalysis(
                task_type=analysis_data.get("task_type", "general"),
                domain=analysis_data.get("domain", "general"),
                required_capabilities=analysis_data.get("required_capabilities", []),
                complexity=analysis_data.get("complexity", "medium"),
                key_challenges=analysis_data.get("key_challenges", []),
                recommended_tools=analysis_data.get("recommended_tools", []),
                knowledge_areas=analysis_data.get("knowledge_areas", []),
            )

            return {
                "task_analysis": task_analysis,
                "persona": response.get("persona", "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½åŠ©æ‰‹ã€‚"),
                "knowledge": response.get("knowledge", ""),
            }

        except Exception as e:
            # é™çº§ç­–ç•¥ï¼šä½¿ç”¨åŸºç¡€é…ç½®
            logger.warning(f"Comprehensive agent design failed, using fallback: {e}")

            # åˆ›å»ºåŸºç¡€çš„ä»»åŠ¡åˆ†æ
            fallback_analysis = TaskAnalysis(
                task_type="general",
                domain="general",
                required_capabilities=["web_research", "file_operations", "research_integration"],
                complexity="medium",
                key_challenges=["ä½¿ç”¨åŸºç¡€é…ç½®"],
                recommended_tools=["web_research", "file_operations", "research_integration"],
                knowledge_areas=["general"],
            )

            return {
                "task_analysis": fallback_analysis,
                "persona": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½åŠ©æ‰‹ï¼Œä¼šå°½åŠ›å®Œæˆä»»åŠ¡ã€‚",
                "knowledge": "åŸºç¡€å·¥ä½œåŸåˆ™ï¼šç†è§£éœ€æ±‚ã€å°è¯•è§£å†³ã€åŠæ—¶åé¦ˆã€‚",
            }

    def _select_tool_bundles(self, task_analysis: TaskAnalysis) -> list[Tool]:
        """åŸºäºåˆ†æç»“æœé€‰æ‹©å·¥å…·åŒ…."""

        selected_tools = []

        # æ ¹æ®æ¨èå·¥å…·åŒ…é€‰æ‹©
        for bundle_name in task_analysis.recommended_tools:
            if bundle_name in self.tool_bundles:
                bundle = self.tool_bundles[bundle_name]
                selected_tools.extend(bundle["tools"])

        # å§‹ç»ˆè¡¥å……é€šç”¨å·¥å…·ï¼Œé¿å…ç­–ç•¥ä¸èƒ½åŠ›æ¸…å•ä¸ä¸€è‡´
        if "travel_services" in self.tool_bundles:
            selected_tools.extend(self.tool_bundles["travel_services"]["tools"])

        if "file_operations" in self.tool_bundles:
            core_file_tools = [
                t for t in self.tool_bundles["file_operations"]["tools"]
                if getattr(t, "name", "") in ["read_file", "write_file", "list_directory"]
            ]
            selected_tools.extend(core_file_tools)

        # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•å·¥å…·ï¼Œæä¾›é»˜è®¤å·¥å…·
        if not selected_tools:
            selected_tools.extend(self.tool_bundles["web_research"]["tools"])
            # åŒæ—¶æä¾›é€šç”¨å·¥å…·ï¼Œé¿å…å•çº¯ä¾èµ–æœç´¢å¯¼è‡´çš„è¯¯é€‰
            if "travel_services" in self.tool_bundles:
                selected_tools.extend(self.tool_bundles["travel_services"]["tools"])
            if "file_operations" in self.tool_bundles:
                selected_tools.extend(self.tool_bundles["file_operations"]["tools"][:3])

        # å»é‡ï¼šæŒ‰å·¥å…·åç§°å»é‡ï¼Œä¿æŒæ·»åŠ é¡ºåº
        unique_tools: dict[str, Tool] = {}
        for tool in selected_tools:
            try:
                tool_name = tool.name  # type: ignore[attr-defined]
            except Exception:
                tool_name = str(tool)
            if tool_name not in unique_tools:
                unique_tools[tool_name] = tool

        return list(unique_tools.values())

    def _tools_to_functions(self, tools: list[Tool]) -> list[dict]:
        """å°† LangChain å·¥å…·è½¬æ¢ä¸º OpenAI Function Calling æ ¼å¼."""

        functions = []
        for tool in tools:
            schema = self._build_function_schema(tool)
            functions.append(
                {
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": schema,
                    },
                }
            )

        return functions

    def _build_function_schema(self, tool: Tool) -> dict[str, Any]:
        """Build JSON schema for a LangChain tool."""

        # StructuredTool already exposes args_schema
        if hasattr(tool, "args_schema") and tool.args_schema:
            try:
                schema = tool.args_schema.schema()
                properties = schema.get("properties", {})
                required = schema.get("required", [])
                return {
                    "type": "object",
                    "properties": properties,
                    "required": required,
                }
            except Exception:
                pass  # fallback to signature-based schema

        signature = inspect.signature(tool.func)
        properties: dict[str, Any] = {}
        required: list[str] = []

        for name, param in signature.parameters.items():
            if name.startswith("_"):
                continue

            annotation = param.annotation if param.annotation is not inspect._empty else str
            properties[name] = self._annotation_to_schema(annotation, name)

            if param.default is inspect._empty:
                required.append(name)

        # additionalProperties é»˜è®¤å…è®¸ï¼Œä¸ºä¿æŒä¸¥æ ¼æ€§å¯è®¾ä¸º False
        schema = {
            "type": "object",
            "properties": properties,
            "required": required,
        }

        return schema

    def _annotation_to_schema(self, annotation: Any, param_name: str) -> dict[str, Any]:
        """Convert Python type annotation to JSON schema fragment."""

        origin = getattr(annotation, "__origin__", None)
        args = getattr(annotation, "__args__", ())

        if annotation in (str, inspect._empty):
            return {"type": "string", "description": f"Parameter {param_name}"}
        if annotation in (int,):
            return {"type": "integer", "description": f"Parameter {param_name}"}
        if annotation in (float,):
            return {"type": "number", "description": f"Parameter {param_name}"}
        if annotation in (bool,):
            return {"type": "boolean", "description": f"Parameter {param_name}"}

        if origin is list or origin is list:
            item_schema = (
                self._annotation_to_schema(args[0], f"{param_name}_item")
                if args
                else {"type": "string"}
            )
            return {
                "type": "array",
                "items": item_schema,
                "description": f"Parameter {param_name}",
            }

        if origin is Union:
            schemas = [
                self._annotation_to_schema(arg, param_name) for arg in args if arg is not type(None)
            ]
            if schemas:
                return {
                    "anyOf": schemas,
                    "description": f"Parameter {param_name}",
                }

        # default fallback
        return {"type": "string", "description": f"Parameter {param_name}"}

    def _compose_prompt_for_functions(
        self,
        persona: str,
        knowledge: str,
        environment: str,
        selected_tools: list | None = None,
        session_id: str | None = None,
    ) -> str:
        """Compose system prompt optimized for Function Calling mode."""

        # æ„å»ºå·¥å…·èƒ½åŠ›æè¿°
        tools_description = ""
        if selected_tools:
            # ä»…å½“å®é™…åŒ…å« currency_convert æ—¶ï¼Œæ‰åŠ å…¥å¯¹åº”ç­–ç•¥è¡Œ
            has_currency_convert = any(
                getattr(tool, "name", "") == "currency_convert" for tool in selected_tools
            )

            currency_strategy_line = (
                "\n- æ¶‰åŠè´§å¸æ¢ç®—/æ±‡ç‡çš„ä»»åŠ¡ï¼Œè¯·ä¼˜å…ˆè°ƒç”¨ travel_services.currency_convertï¼Œä¸è¦å°†ç½‘ç»œæœç´¢ä½œä¸ºé¦–é€‰ï¼ˆé™¤éå·¥å…·ä¸å¯ç”¨æˆ–å¤±è´¥ï¼‰"
                if has_currency_convert
                else ""
            )

            tools_description = f"""

å¯ç”¨å·¥å…·èƒ½åŠ›ï¼š
{self._format_selected_tools_description(selected_tools)}

å·¥å…·ä½¿ç”¨ç­–ç•¥ï¼š
- ä¼˜å…ˆé€‰æ‹©æœ€é€‚åˆçš„å·¥å…·ç±»å‹ï¼Œé¿å…è¿‡åº¦ä¾èµ–å•ä¸€å·¥å…·
- å¦‚æœè¿ç»­ä¸¤æ¬¡æœç´¢æ— æ–°ä¿¡æ¯ï¼Œè¯·æ€»ç»“ç°æœ‰ç»“æœæˆ–è¯·æ±‚é‡æ–°è§„åˆ’
- é‡åˆ°è¶³å¤Ÿä¿¡æ¯æ—¶å¯æå‰æ€»ç»“ï¼Œæ— éœ€æŒç»­æœç´¢ç›´åˆ°è¶…æ—¶
- æ–‡ä»¶æ“ä½œã€æ•°æ®å¤„ç†ç­‰å·¥å…·åŒæ ·é‡è¦ï¼Œæ ¹æ®ä»»åŠ¡æ€§è´¨çµæ´»é€‰æ‹©{currency_strategy_line}"""

        # æ„å»ºæ–‡ä»¶ä¿å­˜è§„èŒƒï¼ˆå¦‚æœæœ‰ session_id ä¸”åŒ…å«æ–‡ä»¶æ“ä½œå·¥å…·ï¼‰
        file_isolation_rule = ""
        if (
            session_id
            and selected_tools
            and any(
                "write_file" in getattr(tool, "name", "")
                or "read_file" in getattr(tool, "name", "")
                or "list_directory" in getattr(tool, "name", "")
                for tool in selected_tools
            )
        ):
            file_isolation_rule = f"""

**âš ï¸ æ–‡ä»¶æ“ä½œå¼ºåˆ¶è§„èŒƒ**ï¼ˆè¯·ä¸¥æ ¼éµå®ˆï¼‰ï¼š
- å½“å‰ Session ID: `{session_id}`
- **æ‰€æœ‰æ–‡ä»¶è·¯å¾„å¿…é¡»ä»¥ `{session_id}/` å¼€å¤´**
- **ğŸš¨ é‡è¦ï¼šå¿…é¡»ä½¿ç”¨å½“å‰Session IDï¼Œä¸è¦ä½¿ç”¨å…¶ä»–IDï¼**
- ç¤ºä¾‹ï¼š
  - âœ… æ­£ç¡®ï¼šwrite_file("{session_id}/research_report.md", content)
  - âœ… æ­£ç¡®ï¼šread_file("{session_id}/temp/data.json")
  - âœ… æ­£ç¡®ï¼šlist_directory("{session_id}/temp")
  - âŒ é”™è¯¯ï¼šwrite_file("research_report.md", ...) - ç¼ºå°‘ session_id å‰ç¼€
  - âŒ é”™è¯¯ï¼šread_file("temp/data.json") - ç¼ºå°‘ session_id å‰ç¼€
  - âŒ é”™è¯¯ï¼šwrite_file("task_20251008_173854/file.md", ...) - ä½¿ç”¨äº†é”™è¯¯çš„session_id
- **è¿™æ˜¯å¼ºåˆ¶è¦æ±‚ï¼Œç¡®ä¿ä¸åŒä»»åŠ¡çš„æ–‡ä»¶å®Œå…¨éš”ç¦»**
- **ğŸ”¥ æ£€æŸ¥æ¸…å•ï¼šæ¯æ¬¡è°ƒç”¨write_fileå‰ï¼Œç¡®è®¤è·¯å¾„ä»¥ `{session_id}/` å¼€å¤´ï¼**
"""

        return f"""{persona}

ç›¸å…³çŸ¥è¯†ï¼š
{knowledge}

ç¯å¢ƒä¿¡æ¯ï¼š
{environment}{tools_description}{file_isolation_rule}

å·¥ä½œæ–¹å¼ï¼š
1. ä»”ç»†åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œåˆ¶å®šæ¸…æ™°çš„æ‰§è¡Œè®¡åˆ’
2. ä½¿ç”¨æä¾›çš„å·¥å…·å‡½æ•°é«˜æ•ˆå®Œæˆä»»åŠ¡
3. é‡åˆ°é—®é¢˜æ—¶å°è¯•å…¶ä»–æ–¹æ³•æˆ–å¯»æ±‚å¸®åŠ©
4. å®Œæˆååœ¨ observation ä¸­æ˜ç¡®è¯´æ˜ "ä»»åŠ¡å·²å®Œæˆ" æˆ– "TASK_COMPLETE"

**ğŸ”¥ ç ”ç©¶ä»»åŠ¡å¿…é¡»ç”Ÿæˆæ–‡ä»¶ï¼**
- å¦‚æœä»»åŠ¡æ¶‰åŠç ”ç©¶ã€è°ƒæŸ¥ã€åˆ†æã€è§„åˆ’ç­‰å†…å®¹ï¼Œå¿…é¡»ä½¿ç”¨ `write_file` å°†ç»“æœä¿å­˜ä¸ºæ–‡ä»¶
- æ–‡ä»¶ååº”è¯¥æ¸…æ™°æè¿°å†…å®¹ï¼Œä½¿ç”¨ `.md` æˆ– `.json` æ ¼å¼
- åªæœç´¢ä¿¡æ¯ä½†ä¸ä¿å­˜æ–‡ä»¶çš„ä»»åŠ¡ä¼šè¢«ç³»ç»Ÿåˆ¤å®šä¸ºå¤±è´¥
- **ğŸš¨ æ–‡ä»¶è·¯å¾„å¿…é¡»ä½¿ç”¨å½“å‰Session IDï¼š`{session_id}/`**
- ç¤ºä¾‹ï¼š
  - âœ… æ­£ç¡®ï¼šæœç´¢ç­¾è¯ä¿¡æ¯ â†’ ä½¿ç”¨ write_file ä¿å­˜ä¸º `{session_id}/visa_requirements.md` â†’ è¯´æ˜"ä»»åŠ¡å·²å®Œæˆ"
  - âŒ é”™è¯¯ï¼šåªæœç´¢ä¿¡æ¯å°±è¯´"ä»»åŠ¡å·²å®Œæˆ"ï¼Œæ²¡æœ‰ä¿å­˜æ–‡ä»¶
  - âŒ é”™è¯¯ï¼šä½¿ç”¨é”™è¯¯çš„session_idè·¯å¾„

ä»»åŠ¡å®Œæˆæ ‡å‡†ï¼š
- å½“ä½ è®¤ä¸ºä»»åŠ¡ç›®æ ‡å·²è¾¾æˆæ—¶ï¼Œåœ¨æœ€åä¸€æ­¥çš„ thought æˆ–å·¥å…·è¾“å‡ºä¸­åŒ…å« "ä»»åŠ¡å·²å®Œæˆ" æˆ– "TASK_COMPLETE"
- å¯¹äºç ”ç©¶ç±»ä»»åŠ¡ï¼Œå¿…é¡»å…ˆè°ƒç”¨ write_file ä¿å­˜ç ”ç©¶ç»“æœï¼Œç„¶åå†è¯´æ˜ä»»åŠ¡å®Œæˆ
- ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«è¿™äº›æ ‡è®°å¹¶ç»“æŸæ‰§è¡Œ

æ³¨æ„äº‹é¡¹ï¼š
- å·¥å…·è°ƒç”¨å°†é€šè¿‡ Function Calling è‡ªåŠ¨å¤„ç†
- ä¸“æ³¨äºä»»åŠ¡é€»è¾‘å’Œç”¨æˆ·ä½“éªŒ
- ä¿æŒä¸“ä¸šã€å‡†ç¡®ã€æœ‰å¸®åŠ©çš„æ€åº¦
- æ˜ç¡®è¡¨è¾¾ä»»åŠ¡å®ŒæˆçŠ¶æ€ï¼Œä¸è¦æ¨¡ç³Šä¸æ¸…
"""

    def _get_environment(self) -> str:
        """è·å–ç¯å¢ƒä¿¡æ¯."""
        return f"""å½“å‰æ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
ç³»ç»Ÿç‰ˆæœ¬ï¼šMini-Aime v0.1.0
æ‰§è¡Œç¯å¢ƒï¼šPython å¼‚æ­¥ç¯å¢ƒ
å¯ç”¨èµ„æºï¼šç½‘ç»œè®¿é—®ã€æ–‡ä»¶ç³»ç»Ÿã€æ•°æ®å¤„ç†"""

    def _build_execution_config(self, task_analysis: TaskAnalysis) -> dict[str, Any]:
        """æ„å»ºæ‰§è¡Œé…ç½®."""

        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´å‚æ•° - ä¼˜åŒ–åçš„é…ç½®ï¼Œå‡å°‘æ­¥æ•°ä»¥é™ä½æˆæœ¬
        complexity_configs = {
            "low": {"max_iterations": 3, "timeout": 120},
            "medium": {"max_iterations": 5, "timeout": 150},
            "high": {"max_iterations": 8, "timeout": 200},
        }

        config = complexity_configs.get(task_analysis.complexity, complexity_configs["medium"])

        config.update(
            {
                "enable_progress_reporting": True,
                "auto_retry_on_error": True,
                "max_retries": 1,
                "log_level": "INFO",
            }
        )

        return config

    def _format_selected_tools_description(self, selected_tools: list) -> str:
        """æ ¼å¼åŒ–é€‰ä¸­å·¥å…·çš„æè¿°ã€‚"""
        if not selected_tools:
            return "æ— ç‰¹å®šå·¥å…·"

        descriptions = []
        for tool in selected_tools:
            if hasattr(tool, "name") and hasattr(tool, "description"):
                descriptions.append(f"- {tool.name}: {tool.description}")
            else:
                descriptions.append(f"- {tool!s}: ä¸“ç”¨å·¥å…·")

        return "\n".join(descriptions)

    def record_tool_recommendation(
        self, task_id: str, recommended_tools: list[str], planner_suggested: list[str] | None = None
    ):
        """è®°å½•å·¥å…·æ¨èï¼Œç”¨äºå·¥å…·é—­ç¯åé¦ˆã€‚"""
        recommendation_record = {
            "task_id": task_id,
            "timestamp": datetime.now().isoformat(),
            "recommended_tools": recommended_tools,
            "planner_suggested": planner_suggested or [],
            "gap_analysis": list(set(recommended_tools) - set(planner_suggested or [])),
        }
        self.tool_recommendations_history.append(recommendation_record)

        # æ›´æ–°å·¥å…·ä½¿ç”¨ç»Ÿè®¡
        for tool in recommended_tools:
            self.tool_usage_stats[tool] = self.tool_usage_stats.get(tool, 0) + 1

    def get_tool_feedback_for_planner(self) -> dict:
        """ä¸º Planner æä¾›å·¥å…·ä½¿ç”¨åé¦ˆï¼Œå½¢æˆé—­ç¯ã€‚"""
        if not self.tool_recommendations_history:
            return {}

        recent_recommendations = self.tool_recommendations_history[-5:]  # æœ€è¿‘5æ¬¡

        # åˆ†æå·¥å…·ä½¿ç”¨æ¨¡å¼
        tool_frequency = {}
        gap_patterns = []

        for record in recent_recommendations:
            for tool in record["recommended_tools"]:
                tool_frequency[tool] = tool_frequency.get(tool, 0) + 1

            if record["gap_analysis"]:
                gap_patterns.extend(record["gap_analysis"])

        return {
            "most_used_tools": sorted(tool_frequency.items(), key=lambda x: x[1], reverse=True)[:3],
            "underused_capabilities": list(set(gap_patterns)),
            "tool_diversity_score": len(tool_frequency) / max(len(self.tool_bundles), 1),
            "recommendations": self._generate_planner_recommendations(tool_frequency, gap_patterns),
        }

    def _generate_planner_recommendations(
        self, tool_frequency: dict, gap_patterns: list
    ) -> list[str]:
        """ç”Ÿæˆç»™ Planner çš„å·¥å…·ä½¿ç”¨å»ºè®®ã€‚"""
        recommendations = []

        # æ£€æŸ¥å·¥å…·ä½¿ç”¨å¤šæ ·æ€§
        if len(tool_frequency) <= 2:
            recommendations.append("å»ºè®®ä»»åŠ¡æ‹†åˆ†æ—¶è€ƒè™‘æ›´å¤šæ ·åŒ–çš„å·¥å…·ç±»å‹")

        # æ£€æŸ¥è¿‡åº¦ä¾èµ–æŸä¸ªå·¥å…·
        if tool_frequency:
            max_usage = max(tool_frequency.values())
            total_usage = sum(tool_frequency.values())
            if max_usage / total_usage > 0.7:
                recommendations.append("é¿å…è¿‡åº¦ä¾èµ–å•ä¸€å·¥å…·ç±»å‹ï¼Œå°è¯•ç»„åˆä½¿ç”¨")

        # æ£€æŸ¥æœªå……åˆ†åˆ©ç”¨çš„å·¥å…·
        if gap_patterns:
            underused = list(set(gap_patterns))
            recommendations.append(f"è€ƒè™‘æ›´å¤šä½¿ç”¨è¿™äº›å·¥å…·ç±»å‹ï¼š{', '.join(underused)}")

        return recommendations

    async def _create_summary_agent(self, task_spec: TaskSpecification) -> "DynamicActor":
        """åˆ›å»ºä¸“é—¨çš„æ±‡æ€»Agentï¼Œç”¨äºæ•´åˆæ‰€æœ‰å­ä»»åŠ¡æŠ¥å‘Šã€‚"""
        from .dynamic_actor import DynamicActor

        # è·å–æ±‡æ€»ä»»åŠ¡çš„å…ƒæ•°æ®
        metadata = task_spec.context
        original_goal = metadata.get("original_goal", "æœªçŸ¥ç›®æ ‡")
        total_subtasks = metadata.get("total_subtasks", 0)
        session_id = metadata.get("session_id", "unknown")

        # é€‰æ‹©å¿…è¦çš„å·¥å…·ï¼šæ–‡ä»¶æ“ä½œ + ç ”ç©¶æ•´åˆ
        tools = []
        if "file_operations" in self.tool_bundles:
            tools.extend(self.tool_bundles["file_operations"]["tools"])
        if "research_integration" in self.tool_bundles:
            tools.extend(self.tool_bundles["research_integration"]["tools"])

        # è½¬æ¢ä¸º Function Calling æ ¼å¼
        functions = self._tools_to_functions(tools)

        system_prompt = f"""# ä½ çš„èº«ä»½ä¸ä½¿å‘½

ä½ æ˜¯ä¸€ä½**èµ„æ·±çš„å†…å®¹æ•´åˆä¸“å®¶å’Œåˆ†æå¸ˆ**ï¼Œæ‹¥æœ‰ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

## ä¸“ä¸šæŠ€èƒ½
- ğŸ“– **æ·±åº¦é˜…è¯»ç†è§£**ï¼šèƒ½å¤Ÿå¿«é€Ÿç†è§£å¤æ‚æ–‡æ¡£çš„æ ¸å¿ƒè¦ç‚¹
- ğŸ”— **ä¿¡æ¯æ•´åˆèƒ½åŠ›**ï¼šå–„äºå‘ç°ä¸åŒå†…å®¹é—´çš„å…³è”å’Œæ¨¡å¼
- ğŸ“Š **ç»“æ„åŒ–æ€ç»´**ï¼šèƒ½å¤Ÿå°†é›¶æ•£ä¿¡æ¯ç»„ç»‡æˆæ¸…æ™°çš„é€»è¾‘ç»“æ„
- ğŸ’¡ **æ´å¯ŸåŠ›**ï¼šä¸ä»…æ€»ç»“äº‹å®ï¼Œæ›´èƒ½æç‚¼æ·±å±‚è§è§£
- âœï¸ **ä¸“ä¸šå†™ä½œ**ï¼šä½¿ç”¨æ¸…æ™°ã€ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€è¡¨è¾¾

## å½“å‰ä»»åŠ¡èƒŒæ™¯

### ç”¨æˆ·åŸå§‹ç›®æ ‡
```
{original_goal}
```

### æ‰§è¡Œæƒ…å†µ
- âœ… å·²å®Œæˆ **{total_subtasks}** ä¸ªå­ä»»åŠ¡
- ğŸ“ Session ID: `{session_id}`
- ğŸ“„ æ¯ä¸ªå­ä»»åŠ¡éƒ½å·²ç”Ÿæˆç‹¬ç«‹çš„è¯¦ç»†æŠ¥å‘Š

### ä½ çš„ä½¿å‘½
å°†æ‰€æœ‰å­ä»»åŠ¡æŠ¥å‘Šæ•´åˆæˆä¸€ä»½**å®Œæ•´ã€è¿è´¯ã€æœ‰æ´å¯ŸåŠ›**çš„æœ€ç»ˆæŠ¥å‘Šï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿï¼š
1. å¿«é€Ÿäº†è§£æ•´ä½“å®Œæˆæƒ…å†µ
2. ç†è§£å„ä»»åŠ¡é—´çš„å…³è”
3. è·å¾—ç»¼åˆæ€§çš„è§è§£å’Œä»·å€¼
4. è¿½æº¯è¯¦ç»†ä¿¡æ¯å’Œå·¥ä»¶

---

**âš ï¸ æ–‡ä»¶æ“ä½œå¼ºåˆ¶è§„èŒƒ**ï¼ˆè¯·ä¸¥æ ¼éµå®ˆï¼‰ï¼š
- å½“å‰ Session ID: `{session_id}`
- **æ‰€æœ‰æ–‡ä»¶è·¯å¾„å¿…é¡»ä»¥ `{session_id}/` å¼€å¤´**
- ç¤ºä¾‹ï¼š
  - âœ… æ­£ç¡®ï¼šread_file("{session_id}/final_report_T1.md")
  - âœ… æ­£ç¡®ï¼šlist_directory("{session_id}")
  - âœ… æ­£ç¡®ï¼šwrite_file("{session_id}/final_report.md", content)
  - âŒ é”™è¯¯ï¼šread_file("final_report_T1.md") - ç¼ºå°‘ session_id å‰ç¼€
  - âŒ é”™è¯¯ï¼šlist_directory("docs") - åº”è¯¥ä½¿ç”¨ "{session_id}"
- **è¿™æ˜¯å¼ºåˆ¶è¦æ±‚ï¼Œç¡®ä¿è¯»å–çš„æ˜¯å½“å‰ä»»åŠ¡çš„æ–‡ä»¶ï¼Œä¸ä¼šè¯»åˆ°å…¶ä»–ä»»åŠ¡çš„æ–‡ä»¶**

---

## å·¥ä½œæµç¨‹

### ç¬¬1æ­¥ï¼šç³»ç»Ÿæ€§é˜…è¯»
1. ä½¿ç”¨ `list_directory("{session_id}")` å·¥å…·åˆ—å‡ºå½“å‰ session ä¸‹çš„æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
2. ä½¿ç”¨ `read_file("{session_id}/æ–‡ä»¶å")` å·¥å…·ä¾æ¬¡é˜…è¯»æ¯ä¸ªå­ä»»åŠ¡æŠ¥å‘Šï¼ˆ**è·¯å¾„å¿…é¡»åŒ…å« {session_id}/**ï¼‰
3. è¾¹è¯»è¾¹è®°å½•ï¼š
   - æ¯ä¸ªä»»åŠ¡çš„æ ¸å¿ƒæˆæœå’Œå®è´¨æ€§å†…å®¹
   - å…³é”®æ•°æ®ã€å‘ç°å’Œæ´å¯Ÿ
   - ç”¨æˆ·éœ€è¦çš„å…·ä½“ä¿¡æ¯ï¼ˆä¸è¦è®°å½•ç³»ç»Ÿæ‰§è¡Œè¿‡ç¨‹ï¼‰
4. æ³¨æ„ä»»åŠ¡é—´çš„é€»è¾‘å…³ç³»å’Œå†…å®¹è¿è´¯æ€§

### ç¬¬1.5æ­¥ï¼šæ™ºèƒ½æ•´åˆç ”ç©¶æ•°æ®
**ğŸš¨ å…³é”®æ­¥éª¤ï¼šä½¿ç”¨æ™ºèƒ½å·¥å…·æ•´åˆæ‰€æœ‰çœŸå®çš„ç ”ç©¶æˆæœï¼**

åœ¨è¯»å–å­ä»»åŠ¡æŠ¥å‘Šåï¼Œå¿…é¡»æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

1. **ä¼˜å…ˆä½¿ç”¨æ™ºèƒ½æ•´åˆå·¥å…·**ï¼š
   - ä½¿ç”¨ `integrate_research` å·¥å…·æ™ºèƒ½å‘ç°å’Œæ•´åˆä»»åŠ¡ç›®å½•ä¸‹çš„æ‰€æœ‰ç ”ç©¶æ–‡ä»¶
   - è¿™ä¸ªå·¥å…·ä¼šè‡ªåŠ¨æ‰«æ `{session_id}/` ç›®å½•ï¼Œæ‰¾åˆ°æ‰€æœ‰ç ”ç©¶æ–‡ä»¶ï¼ˆæ’é™¤ `final_report_*.md`ï¼‰
   - ä½¿ç”¨LLMåˆ†ææ¯ä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯å’Œå…·ä½“æ•°æ®

   **å…·ä½“è°ƒç”¨ç¤ºä¾‹**ï¼š
   ```
   integrate_research(
       task_directory="{session_id}",
       output_file="{session_id}/research_integration_report.md",
       original_goal="{original_goal}"
   )
   ```

2. **æ‰‹åŠ¨è¡¥å……ï¼ˆå¦‚æœéœ€è¦ï¼‰**ï¼š
   - å¦‚æœæ™ºèƒ½æ•´åˆå·¥å…·é—æ¼äº†æŸäº›æ–‡ä»¶ï¼Œæ‰‹åŠ¨ä½¿ç”¨ `read_file` è¯»å–
   - ç‰¹åˆ«å…³æ³¨å­ä»»åŠ¡æŠ¥å‘Šä¸­"å¼•ç”¨ä¸å·¥ä»¶"éƒ¨åˆ†æåˆ°çš„æ–‡ä»¶
   - ç¡®ä¿è·å–æ‰€æœ‰åŸå§‹çš„ç ”ç©¶æ•°æ®å’Œè¯¦ç»†å†…å®¹

3. **éªŒè¯æ•°æ®å®Œæ•´æ€§**ï¼š
   - ç¡®ä¿æ•´åˆäº†æ‰€æœ‰å­ä»»åŠ¡çš„ç ”ç©¶æˆæœ
   - æ£€æŸ¥æ˜¯å¦åŒ…å«å…·ä½“æ•°æ®ï¼ˆä»·æ ¼ã€æ—¶é—´ã€åœ°ç‚¹ç­‰ï¼‰
   - ä¸è¦é—æ¼ä»»ä½•é‡è¦çš„ç ”ç©¶å‘ç°

4. **ç”ŸæˆåŸºäºçœŸå®æ•°æ®çš„æŠ¥å‘Š**ï¼š
   - ä½¿ç”¨æ•´åˆçš„ç ”ç©¶æ•°æ®ç”Ÿæˆç»¼åˆæŠ¥å‘Š
   - ç¡®ä¿æŠ¥å‘ŠåŒ…å«å…·ä½“çš„ç ”ç©¶æ•°æ®ï¼Œè€Œä¸æ˜¯é€šç”¨æ¨¡æ¿
   - çªå‡ºæ¯ä¸ªä»»åŠ¡çš„å®é™…äº§å‡ºå’Œå‘ç°

**âš ï¸ é‡è¦æé†’**ï¼š
- ä¼˜å…ˆä½¿ç”¨ `integrate_research` å·¥å…·è¿›è¡Œæ™ºèƒ½æ•´åˆ
- å­ä»»åŠ¡æŠ¥å‘Šå¯èƒ½åªæ˜¯ç»“æ„åŒ–å£³ï¼ŒçœŸå®å†…å®¹åœ¨ç ”ç©¶æ–‡ä»¶ä¸­
- å¿…é¡»åŸºäºå®é™…ç ”ç©¶æ•°æ®ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š

### ç¬¬2æ­¥ï¼šä¿¡æ¯æå–ä¸æ•´åˆ
é’ˆå¯¹æ¯ä¸ªå­ä»»åŠ¡æŠ¥å‘Šå’Œç ”ç©¶æ–‡ä»¶ï¼Œæå–ï¼š
- **å®è´¨æ€§å†…å®¹**ï¼šå…·ä½“çš„æ•°æ®ã€ä¿¡æ¯ã€å»ºè®®
- **å…³é”®å‘ç°**ï¼šé‡è¦çš„å‘ç°å’Œæ´å¯Ÿ
- **å¯æ“ä½œä¿¡æ¯**ï¼šç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨çš„å†…å®¹

åŒæ—¶æ€è€ƒï¼š
- å¦‚ä½•å°†è¿™äº›å†…å®¹æœ‰æœºåœ°æ•´åˆåœ¨ä¸€èµ·ï¼Ÿ
- å¦‚ä½•è®©æŠ¥å‘Šç»“æ„æ¸…æ™°ã€æ˜“è¯»ï¼Ÿ
- ç”¨æˆ·æœ€å…³å¿ƒä»€ä¹ˆä¿¡æ¯ï¼Ÿ

### ç¬¬3æ­¥ï¼šç»¼åˆåˆ†æ
- ğŸ“Š **æ•´ä½“æ•´åˆ**ï¼šå°†æ‰€æœ‰å†…å®¹æ•´åˆæˆè¿è´¯çš„æŠ¥å‘Š
- ğŸ”— **é€»è¾‘ç»„ç»‡**ï¼šæŒ‰ç…§ç”¨æˆ·çš„é˜…è¯»ä¹ æƒ¯ç»„ç»‡å†…å®¹
- ğŸ’¡ **ä»·å€¼æç‚¼**ï¼šæä¾›æœ‰ä»·å€¼çš„æ€»ç»“å’Œå»ºè®®
- ğŸ¯ **ç”¨æˆ·å¯¼å‘**ï¼šç¡®ä¿æ‰€æœ‰å†…å®¹å¯¹ç”¨æˆ·æœ‰å®é™…ä»·å€¼

### ç¬¬4æ­¥ï¼šæ’°å†™æœ€ç»ˆæŠ¥å‘Š
**ğŸš¨ è¿™æ˜¯ä½ çš„æ ¸å¿ƒä»»åŠ¡ï¼ä½ å¿…é¡»å®Œæˆè¿™ä¸€æ­¥ï¼**

ä½¿ç”¨ `write_file` å·¥å…·ï¼Œ**å¿…é¡»**å°†æŠ¥å‘Šä¿å­˜åˆ°ä»¥ä¸‹è·¯å¾„ï¼ˆè¯·ä¸¥æ ¼éµå®ˆï¼‰ï¼š

**æ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»ä½¿ç”¨æ­¤è·¯å¾„ï¼‰**ï¼š
```
{session_id}/final_report.md
```

**âš ï¸ å…³é”®è¦æ±‚**ï¼š
- ğŸ”¥ **è¿™æ˜¯ä½ çš„ä¸»è¦ç›®æ ‡**ï¼šç”Ÿæˆé¢å‘æœ€ç»ˆç”¨æˆ·çš„ã€å®Œæ•´çš„ã€è¯¦å°½çš„ã€åŸºäºæ‰€æœ‰ç ”ç©¶æ•°æ®çš„ç»¼åˆæŠ¥å‘Š
- ğŸ”¥ **ä¸è¦åªæ˜¯è¯»å–æ–‡ä»¶**ï¼šä½ å¿…é¡»è°ƒç”¨ `write_file` ç”ŸæˆæŠ¥å‘Š
- ğŸ”¥ **è·¯å¾„**ï¼š`{session_id}/final_report.md`ï¼ˆä¸è¦ä»¥ `docs/` å¼€å¤´ï¼‰
- ğŸ”¥ **æ–‡ä»¶å**ï¼šå¿…é¡»æ˜¯ `final_report.md`
- ğŸ”¥ **å†…å®¹ä¸°å¯Œæ€§è¦æ±‚ï¼ˆéå¸¸é‡è¦ï¼ï¼‰**ï¼š
  - **å¿…é¡»è¯¦å°½**ï¼šæŠ¥å‘Šé•¿åº¦åº”è¯¥è¶³å¤Ÿè¯¦ç»†ï¼Œå……åˆ†å±•ç¤ºæ‰€æœ‰ç ”ç©¶æˆæœ
  - **å……åˆ†åˆ©ç”¨æ‰€æœ‰æ•°æ®**ï¼šæ¯ä¸ªå­ä»»åŠ¡çš„ç ”ç©¶ç»“æœã€æ¯æ¬¡ function_calling è·å–çš„ä¿¡æ¯éƒ½å¿…é¡»ä½“ç°åœ¨æŠ¥å‘Šä¸­
  - **å…·ä½“åŒ–**ï¼šæ‰€æœ‰ä»·æ ¼ã€æ—¶é—´ã€åœ°ç‚¹ã€è”ç³»æ–¹å¼ã€ç½‘å€ã€å…·ä½“å»ºè®®éƒ½è¦åŒ…å«
  - **ä¸èƒ½é—æ¼**ï¼šå¦‚æœç ”ç©¶æ–‡ä»¶ä¸­æåˆ°äº†æŸä¸ªæ™¯ç‚¹ã€æŸä¸ªä»·æ ¼ã€æŸä¸ªå»ºè®®ï¼ŒæŠ¥å‘Šä¸­å¿…é¡»ä½“ç°
- ğŸ”¥ **å†…å®¹æ ¼å¼**ï¼š
  - å¦‚æœåŸå§‹ç›®æ ‡åŒ…å«æ—¶é—´è§„åˆ’ï¼ˆå¦‚"Xå‘¨""Xä¸ªæœˆ""Xå¤©"è®¡åˆ’ç­‰ï¼‰ï¼Œå¿…é¡»ç”ŸæˆæŒ‰æ—¶é—´åˆ†é˜¶æ®µçš„è¯¦ç»†è®¡åˆ’è¡¨
  - æ¯ä¸ªæ—¶é—´æ®µè¦æœ‰å…·ä½“çš„æ´»åŠ¨å®‰æ’ã€é¢„ç®—æ˜ç»†ã€å®ç”¨å»ºè®®
  - æŠ¥å‘Šå¿…é¡»æ˜¯ç”¨æˆ·å‹å¥½çš„ã€å¯ç›´æ¥ä½¿ç”¨çš„æ–‡æ¡£ï¼Œè€Œä¸æ˜¯æŠ€æœ¯æ€§çš„æ‰§è¡ŒæŠ¥å‘Š
  - ç¡®ä¿åŒ…å«å…·ä½“çš„ã€å¯æ“ä½œçš„å»ºè®®å’Œæ•°æ®

**âŒ ä¸¥é‡é”™è¯¯ï¼ˆç»å¯¹ç¦æ­¢ï¼‰**ï¼š
- åªè¯»å–1-2ä¸ªæ–‡ä»¶å°±ç»“æŸ âŒâŒâŒ
- ç”Ÿæˆé€šç”¨çš„æ¨¡æ¿è€Œä¸åŒ…å«å…·ä½“ç ”ç©¶æ•°æ® âŒâŒâŒ
- æŠ¥å‘Šå†…å®¹å¤ªç®€ç•¥ï¼Œæ²¡æœ‰å……åˆ†åˆ©ç”¨ç ”ç©¶æ•°æ® âŒâŒâŒ
- é—æ¼äº†æŸäº›ç ”ç©¶æ–‡ä»¶ä¸­çš„é‡è¦ä¿¡æ¯ âŒâŒâŒ
- ç”ŸæˆæŠ€æœ¯æ€§çš„ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Šï¼ˆåŒ…å«"ä»»åŠ¡ID"ã€"æ‰§è¡Œæ­¥æ•°"ç­‰å…ƒæ•°æ®ï¼‰âŒâŒâŒ

**âœ… æ­£ç¡®è¡Œä¸ºï¼ˆå¿…é¡»éµå®ˆï¼‰**ï¼š
1. **ç³»ç»Ÿæ€§è¯»å–**ï¼šä½¿ç”¨ `list_directory` åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶ï¼Œç„¶åç”¨ `read_file` é€ä¸ªè¯»å–æ‰€æœ‰ .md å’Œ .json æ–‡ä»¶ï¼ˆæ’é™¤ final_report_*.mdï¼‰
2. **å…¨é¢æå–**ï¼šæå–æ¯ä¸ªæ–‡ä»¶ä¸­çš„æ‰€æœ‰å…·ä½“æ•°æ®ï¼š
   - ä»·æ ¼ä¿¡æ¯ï¼ˆæœºç¥¨ã€ä½å®¿ã€é¤é¥®ã€æ´»åŠ¨ç­‰ï¼‰
   - æ—¶é—´ä¿¡æ¯ï¼ˆæœ€ä½³æ—¶é—´ã€æ¯æ—¥å®‰æ’ç­‰ï¼‰
   - åœ°ç‚¹ä¿¡æ¯ï¼ˆæ™¯ç‚¹ã€é…’åº—ã€äº¤é€šæ¢çº½ç­‰ï¼‰
   - å®ç”¨å»ºè®®ï¼ˆç­¾è¯æµç¨‹ã€æ³¨æ„äº‹é¡¹ç­‰ï¼‰
   - æ‰€æœ‰å…¶ä»–å…·ä½“æ•°æ®
3. **ä¸°å¯Œæ•´åˆ**ï¼šå°†æ‰€æœ‰æ•°æ®æ•´åˆæˆè¯¦å°½çš„æŠ¥å‘Šï¼Œç¡®ä¿ï¼š
   - æ¯ä¸ªç ”ç©¶ä¸»é¢˜éƒ½æœ‰è¯¦ç»†é˜è¿°
   - æ‰€æœ‰å…·ä½“æ•°æ®éƒ½è¢«åŒ…å«
   - æŠ¥å‘Šé•¿åº¦è¶³å¤Ÿè¯¦ç»†ï¼ˆä¸è¦å¤ªç®€ç•¥ï¼‰
4. **ä¿å­˜æŠ¥å‘Š**ï¼šè°ƒç”¨ `write_file` ä¿å­˜åˆ° `{session_id}/final_report.md`

**ğŸ“ å†…å®¹ä¸°å¯Œåº¦æ£€æŸ¥æ¸…å•**ï¼š
- âœ… æ˜¯å¦åŒ…å«äº†æ‰€æœ‰å­ä»»åŠ¡çš„ç ”ç©¶æˆæœï¼Ÿ
- âœ… æ˜¯å¦åŒ…å«äº†æ‰€æœ‰å…·ä½“çš„ä»·æ ¼ä¿¡æ¯ï¼Ÿ
- âœ… æ˜¯å¦åŒ…å«äº†æ‰€æœ‰å…·ä½“çš„æ—¶é—´å®‰æ’ï¼Ÿ
- âœ… æ˜¯å¦åŒ…å«äº†æ‰€æœ‰æ™¯ç‚¹å’Œåœ°ç‚¹çš„è¯¦ç»†ä»‹ç»ï¼Ÿ
- âœ… æ˜¯å¦åŒ…å«äº†æ‰€æœ‰å®ç”¨å»ºè®®å’Œæ³¨æ„äº‹é¡¹ï¼Ÿ
- âœ… æŠ¥å‘Šé•¿åº¦æ˜¯å¦è¶³å¤Ÿè¯¦ç»†ï¼ˆè€Œä¸æ˜¯å‡ æ®µè¯çš„æ‘˜è¦ï¼‰ï¼Ÿ

---

## æœ€ç»ˆæŠ¥å‘Šæ ¼å¼è§„èŒƒ

**ğŸ¯ æ ¸å¿ƒåŸåˆ™ï¼šç”¨æˆ·å‹å¥½ã€å®ç”¨æ€§å¼ºã€å†…å®¹è¯¦å®**

æŠ¥å‘Šåº”è¯¥æ˜¯æ™®é€šç”¨æˆ·å¯ä»¥ç›´æ¥é˜…è¯»å’Œä½¿ç”¨çš„æ–‡æ¡£ï¼Œè€Œä¸æ˜¯æŠ€æœ¯æ€§çš„æ‰§è¡ŒæŠ¥å‘Šã€‚

### ğŸ“‹ æ¨èæ ¼å¼ç»“æ„

æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„æ ¼å¼ï¼š

#### æ ¼å¼Aï¼šæ—¶é—´è§„åˆ’ç±»ï¼ˆå­¦ä¹ è®¡åˆ’ã€é¡¹ç›®è®¡åˆ’ç­‰ï¼‰

**é‡è¦æç¤ºï¼šä»¥ä¸‹æ ¼å¼åªæ˜¯ç»“æ„ç¤ºæ„ï¼Œå®é™…æŠ¥å‘Šå†…å®¹å¿…é¡»éå¸¸è¯¦å°½ï¼**

```markdown
# {original_goal}

## ğŸ“‹ æ¦‚è§ˆ
- **æ€»æ—¶é•¿**ï¼š[å…·ä½“å¤©æ•°/å‘¨æ•°/æœˆæ•°]
- **ä¸»è¦åŒºåŸŸ**ï¼š[åˆ—å‡ºæ‰€æœ‰æ¶‰åŠçš„åœ°åŒº/ä¸»é¢˜]
- **æ€»é¢„ç®—**ï¼š[å…·ä½“é‡‘é¢ï¼ŒåŒ…æ‹¬æ‰€æœ‰æ˜ç»†]
- **æœ€ä½³æ—¶é—´**ï¼š[åŸºäºç ”ç©¶çš„å…·ä½“å»ºè®®]
- **è¡Œç¨‹äº®ç‚¹**ï¼š[åˆ—å‡ºæ‰€æœ‰é‡è¦æ™¯ç‚¹/æ´»åŠ¨]

## ğŸ—“ï¸ ç¬¬ä¸€é˜¶æ®µï¼š[é˜¶æ®µåç§°]ï¼ˆç¬¬X-Yå‘¨/å¤©ï¼‰

### ğŸ¯ æœ¬é˜¶æ®µç›®æ ‡
[æ¸…æ™°çš„ç›®æ ‡è¯´æ˜]

### ğŸ“… è¯¦ç»†æ—¥ç¨‹
**ç¬¬Xå¤©ï¼š[åœ°ç‚¹] - [ä¸»é¢˜]**
- **ä¸Šåˆ**ï¼š[å…·ä½“æ´»åŠ¨ï¼ŒåŒ…æ‹¬åœ°ç‚¹åç§°ã€åœ°å€ã€å¼€æ”¾æ—¶é—´]
  - æ´»åŠ¨1ï¼š[åç§°ã€ç®€ä»‹ã€é—¨ç¥¨ä»·æ ¼ã€é¢„è®¡æ—¶é—´]
  - æ´»åŠ¨2ï¼š[åç§°ã€ç®€ä»‹ã€é—¨ç¥¨ä»·æ ¼ã€é¢„è®¡æ—¶é—´]
- **ä¸‹åˆ**ï¼š[å…·ä½“æ´»åŠ¨]
  - æ´»åŠ¨3ï¼š[è¯¦ç»†ä¿¡æ¯]
- **æ™šä¸Š**ï¼š[å…·ä½“æ´»åŠ¨]
  - é¤å…æ¨èï¼š[åç§°ã€ç‰¹è‰²èœã€äººå‡æ¶ˆè´¹]
- **ä½å®¿**ï¼š[é…’åº—åç§°ã€ä»·æ ¼åŒºé—´ã€é¢„è®¢å»ºè®®]

**ç¬¬X+1å¤©ï¼š[åœ°ç‚¹] - [ä¸»é¢˜]**
[ç»§ç»­è¯¦ç»†åˆ—å‡ºæ¯å¤©çš„å®‰æ’...]

### ğŸ’° æœ¬é˜¶æ®µé¢„ç®—æ˜ç»†
| é¡¹ç›® | å…·ä½“å†…å®¹ | å•ä»· | æ•°é‡ | å°è®¡ |
|------|---------|------|------|------|
| ä½å®¿ | [é…’åº—ç±»å‹] | Â¥XXX/æ™š | Xæ™š | Â¥XXX |
| é¤é¥® | [æ¯æ—¥å¹³å‡] | Â¥XXX/å¤© | Xå¤© | Â¥XXX |
| äº¤é€š | [å…·ä½“æ–¹å¼] | Â¥XXX | - | Â¥XXX |
| é—¨ç¥¨ | [æ™¯ç‚¹åç§°] | Â¥XXX | Xäºº | Â¥XXX |
| **é˜¶æ®µå°è®¡** | | | | **Â¥XXX** |

### ğŸš— äº¤é€šå®‰æ’
- **åˆ°è¾¾äº¤é€š**ï¼š[å…·ä½“æ–¹å¼ã€è·¯çº¿ã€ä»·æ ¼ã€æ—¶é•¿]
- **åŒºåŸŸå†…äº¤é€š**ï¼š[ç§Ÿè½¦/å…¬äº¤/å…¶ä»–ï¼Œå…·ä½“è´¹ç”¨å’Œå»ºè®®]
- **ç¦»å¼€äº¤é€š**ï¼š[å…·ä½“æ–¹å¼ã€è·¯çº¿ã€ä»·æ ¼ã€æ—¶é•¿]

### ğŸ“Œ é‡è¦æç¤º
- âš ï¸ [å…·ä½“æ³¨æ„äº‹é¡¹1]
- âš ï¸ [å…·ä½“æ³¨æ„äº‹é¡¹2]
- ğŸ’¡ [å®ç”¨å»ºè®®1]
- ğŸ’¡ [å®ç”¨å»ºè®®2]

### ğŸ¨ ä½å®¿æ¨è
1. **[é…’åº—/æ°‘å®¿åç§°]**
   - ä½ç½®ï¼š[å…·ä½“åœ°å€]
   - ä»·æ ¼ï¼šÂ¥XXX-XXX/æ™š
   - ç‰¹ç‚¹ï¼š[è®¾æ–½ã€ä¼˜åŠ¿]
   - é¢„è®¢å»ºè®®ï¼š[æå‰æ—¶é—´ã€å¹³å°]

## ğŸ—“ï¸ ç¬¬äºŒé˜¶æ®µï¼š[é˜¶æ®µåç§°]ï¼ˆç¬¬X-Yå‘¨/å¤©ï¼‰
[æŒ‰ç…§åŒæ ·è¯¦ç»†çš„æ ¼å¼ç»§ç»­...]

## ğŸ’µ æ€»é¢„ç®—ä¼°ç®—

### è¯¦ç»†è´¹ç”¨æ¸…å•
| å¤§ç±» | æ˜ç»† | é‡‘é¢ |
|------|------|------|
| **å›½é™…äº¤é€š** | | |
| å¾€è¿”æœºç¥¨ | [å‡ºå‘åœ°-ç›®çš„åœ°] | Â¥XXX |
| **å¢ƒå†…äº¤é€š** | | |
| ç§Ÿè½¦ | [å¤©æ•°ã€è½¦å‹] | Â¥XXX |
| æ²¹è´¹ | [é¢„ä¼°] | Â¥XXX |
| åœè½¦è´¹ | [é¢„ä¼°] | Â¥XXX |
| **ä½å®¿** | | |
| ç¬¬ä¸€é˜¶æ®µ | [Xæ™š] | Â¥XXX |
| ç¬¬äºŒé˜¶æ®µ | [Xæ™š] | Â¥XXX |
| **é¤é¥®** | | |
| æ—¥å¸¸é¤é¥® | [Xå¤© Ã— Â¥XXX] | Â¥XXX |
| ç‰¹è‰²é¤å… | [Xæ¬¡] | Â¥XXX |
| **æ´»åŠ¨é—¨ç¥¨** | | |
| [å…·ä½“æ´»åŠ¨1] | | Â¥XXX |
| [å…·ä½“æ´»åŠ¨2] | | Â¥XXX |
| **å…¶ä»–** | | |
| ç­¾è¯ | | Â¥XXX |
| ä¿é™© | | Â¥XXX |
| åº”æ€¥é¢„å¤‡é‡‘ | | Â¥XXX |
| **æ€»è®¡** | | **Â¥XX,XXX** |

## ğŸ’¡ å®ç”¨å»ºè®®

### ç­¾è¯åŠç†
[è¯¦ç»†çš„ç­¾è¯æµç¨‹ã€ææ–™æ¸…å•ã€åŠç†æ—¶é—´]

### æœ€ä½³æ—¶é—´
[åŸºäºç ”ç©¶çš„è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬å¤©æ°”ã€èŠ‚å‡æ—¥ã€ä»·æ ¼ç­‰å› ç´ ]

### å¿…å¤‡ç‰©å“æ¸…å•
- [åˆ†ç±»åˆ—å‡ºæ‰€æœ‰å»ºè®®æºå¸¦çš„ç‰©å“]

### å½“åœ°å®ç”¨ä¿¡æ¯
- **ç´§æ€¥ç”µè¯**ï¼š[å…·ä½“å·ç ]
- **å¸¸ç”¨APP**ï¼š[åç§°å’Œç”¨é€”]
- **æ–‡åŒ–ä¹ ä¿—**ï¼š[éœ€è¦æ³¨æ„çš„äº‹é¡¹]

## ğŸ”— å‚è€ƒèµ„æº
- [é‡è¦ç½‘ç«™é“¾æ¥å’Œè¯´æ˜]
- [æœ‰ç”¨çš„æ–‡æ¡£å’ŒæŒ‡å—]
- [è”ç³»æ–¹å¼å’Œå’¨è¯¢æ¸ é“]
```

**âš ï¸ å†…å®¹ä¸°å¯Œåº¦æ ‡å‡†**ï¼š
- å¦‚æœæ˜¯ä¸¤ä¸ªæœˆè®¡åˆ’ï¼ŒæŠ¥å‘Šåº”è¯¥åŒ…å«60å¤©çš„è¯¦ç»†å®‰æ’
- æ¯å¤©çš„å®‰æ’è¦å…·ä½“åˆ°æ´»åŠ¨ã€åœ°ç‚¹ã€æ—¶é—´ã€ä»·æ ¼
- æ‰€æœ‰ä»·æ ¼ä¿¡æ¯å¿…é¡»æ¥è‡ªç ”ç©¶æ•°æ®ï¼Œä¸èƒ½ç©ºç¼º
- æ™¯ç‚¹ä»‹ç»è¦åŒ…å«åç§°ã€ç‰¹è‰²ã€é—¨ç¥¨ã€å¼€æ”¾æ—¶é—´ç­‰
- ä½å®¿æ¨èè¦åŒ…å«å…·ä½“åç§°ã€ä»·æ ¼åŒºé—´ã€ç‰¹ç‚¹

#### æ ¼å¼Bï¼šç ”ç©¶æŠ¥å‘Šç±»ï¼ˆæŠ€æœ¯è°ƒç ”ã€å¸‚åœºåˆ†æç­‰ï¼‰

```markdown
# {original_goal} - ç ”ç©¶æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
[æ ¸å¿ƒå‘ç°å’Œç»“è®ºçš„ç®€è¦æ€»ç»“]

## ç ”ç©¶èƒŒæ™¯
[ä¸ºä»€ä¹ˆè¿›è¡Œè¿™é¡¹ç ”ç©¶ï¼Œç›®æ ‡æ˜¯ä»€ä¹ˆ]

## ç ”ç©¶å‘ç°

### ä¸»é¢˜1ï¼š[å…·ä½“ä¸»é¢˜]
[è¯¦ç»†çš„ç ”ç©¶å†…å®¹å’Œæ•°æ®]

### ä¸»é¢˜2ï¼š[å…·ä½“ä¸»é¢˜]
[è¯¦ç»†çš„ç ”ç©¶å†…å®¹å’Œæ•°æ®]

## ç»¼åˆåˆ†æ
[è·¨ä¸»é¢˜çš„åˆ†æå’Œæ´å¯Ÿ]

## ç»“è®ºä¸å»ºè®®
[åŸºäºç ”ç©¶çš„å…·ä½“å»ºè®®]

## å‚è€ƒèµ„æ–™
[æ¥æºã€é“¾æ¥ç­‰]
```

**âš ï¸ æ ¼å¼è¦æ±‚**ï¼š
- **ç¦æ­¢**åŒ…å«ï¼šä»»åŠ¡IDã€Session IDã€æ‰§è¡Œæ­¥æ•°ç­‰æŠ€æœ¯å…ƒæ•°æ®
- **å¿…é¡»**åŒ…å«ï¼šå…·ä½“çš„ç ”ç©¶æ•°æ®ã€ä»·æ ¼ã€æ—¶é—´ã€åœ°ç‚¹ã€é“¾æ¥ç­‰å®ç”¨ä¿¡æ¯
- **çªå‡º**å¯æ“ä½œæ€§ï¼šç¡®ä¿ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨æŠ¥å‘Šä¸­çš„ä¿¡æ¯

---

### ğŸ“ å†…å®¹è´¨é‡è¦æ±‚

**æ ¸å¿ƒåŸåˆ™ï¼šç”¨æˆ·ä»·å€¼ç¬¬ä¸€**

1. **å†…å®¹å®Œæ•´æ€§**ï¼š
   - å¿…é¡»æ•´åˆæ‰€æœ‰å­ä»»åŠ¡çš„ç ”ç©¶æˆæœå’Œæ•°æ®
   - ç¡®ä¿åŒ…å«å…·ä½“ä¿¡æ¯ï¼ˆä»·æ ¼ã€æ—¶é—´ã€åœ°ç‚¹ã€è”ç³»æ–¹å¼ç­‰ï¼‰
   - ä¸é—æ¼é‡è¦çš„å‘ç°å’Œå»ºè®®

2. **å®ç”¨æ€§**ï¼š
   - ç”¨æˆ·å¯ä»¥ç›´æ¥æ ¹æ®æŠ¥å‘Šé‡‡å–è¡ŒåŠ¨
   - ä¿¡æ¯å…·ä½“ã€å¯æ“ä½œ
   - é¿å…ç©ºæ´çš„æè¿°å’Œé€šç”¨æ¨¡æ¿

3. **ç»“æ„æ¸…æ™°**ï¼š
   - ä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜å’Œå­æ ‡é¢˜
   - åˆç†ä½¿ç”¨åˆ—è¡¨ã€è¡¨æ ¼ç­‰æ ¼å¼
   - é€»è¾‘è¿è´¯ï¼Œæ˜“äºé˜…è¯»

4. **æ•°æ®å‡†ç¡®**ï¼š
   - æ‰€æœ‰æ•°æ®æ¥æºäºå®é™…çš„ç ”ç©¶æ–‡ä»¶
   - ä¸ç¼–é€ æˆ–çŒœæµ‹ä¿¡æ¯
   - å¼•ç”¨å…·ä½“çš„æ•°æ®å’Œå‘ç°

---

## æ³¨æ„äº‹é¡¹

âš ï¸ **å¿…é¡»åš**ï¼š
- ä»”ç»†é˜…è¯»æ‰€æœ‰å­ä»»åŠ¡æŠ¥å‘Š
- åŸºäºå®é™…å†…å®¹è¿›è¡Œåˆ†æ
- éµå¾ªä¸‰éƒ¨åˆ†æ ¼å¼è§„èŒƒ
- æä¾›æ·±åº¦æ´å¯Ÿï¼Œä¸æ˜¯ç®€å•æ€»ç»“
- ä¿æŒåŸå§‹ç›®æ ‡çš„æ ¸å¿ƒæ„å›¾

âš ï¸ **ç¦æ­¢**ï¼š
- ç¼–é€ æŠ¥å‘Šä¸­æ²¡æœ‰çš„å†…å®¹
- ç®€å•å¤åˆ¶ç²˜è´´å­ä»»åŠ¡æŠ¥å‘Š
- å¿½ç•¥ä»»åŠ¡é—´çš„å…³è”
- ä½¿ç”¨æ¨¡ç³Šæˆ–ç¬¼ç»Ÿçš„è¡¨è¿°

---

## å¼€å§‹æ‰§è¡Œ

**ğŸš¨ é‡è¦æé†’**ï¼š
- ä½ çš„ä»»åŠ¡æ˜¯ç”Ÿæˆ**åŠå¹´å­¦ä¹ è®¡åˆ’**ï¼Œä¸æ˜¯è®°å½•æ‰§è¡Œè¿‡ç¨‹
- å¿…é¡»è°ƒç”¨ `write_file` å·¥å…·ç”Ÿæˆ `{session_id}/final_report.md`
- ä¸è¦é™·å…¥æ— é™è¯»å–å¾ªç¯ï¼Œè¯»å–å®Œå¿…è¦æ–‡ä»¶åç«‹å³ç”ŸæˆæŠ¥å‘Š

ç°åœ¨ï¼Œè¯·å¼€å§‹ç³»ç»Ÿæ€§åœ°é˜…è¯»æ‰€æœ‰å­ä»»åŠ¡æŠ¥å‘Šï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œè¿›è¡Œç»¼åˆåˆ†æï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä»½é«˜è´¨é‡çš„ã€ç¬¦åˆè§„èŒƒçš„æœ€ç»ˆæ±‡æ€»æŠ¥å‘Šã€‚

**è®°ä½**ï¼šä½ çš„ç›®æ ‡ä¸æ˜¯å®Œæˆä¸€ä¸ªå½¢å¼åŒ–çš„æ–‡æ¡£ï¼Œè€Œæ˜¯ä¸ºç”¨æˆ·æä¾›çœŸæ­£æœ‰ä»·å€¼çš„ã€æœ‰æ´å¯ŸåŠ›çš„ç»¼åˆæ€§åˆ†ææŠ¥å‘Šï¼

**ğŸ”¥ å…³é”®**ï¼šè¯»å–æ–‡ä»¶åï¼Œå¿…é¡»è°ƒç”¨ `write_file` ç”Ÿæˆå­¦ä¹ è®¡åˆ’ï¼

åŠ æ²¹ï¼ğŸ’ª
"""

        # åˆ›å»ºæ±‡æ€»Agenté…ç½®
        config = ActorConfiguration(
            actor_id=f"summary_agent_{uuid.uuid4().hex[:8]}",
            task_id=task_spec.task_id,
            persona="èµ„æ·±å†…å®¹æ•´åˆä¸“å®¶ä¸åˆ†æå¸ˆ",
            tools=[tool.name for tool in tools],
            knowledge=f"åŸå§‹ç›®æ ‡ï¼š{original_goal}\nå­ä»»åŠ¡æ•°ï¼š{total_subtasks}\nSession: {session_id}",
            system_prompt=system_prompt,
            execution_config={
                "max_iterations": 10,
                "timeout": 300,
                "require_detailed_report": True,
            },
            metadata={
                "created_at": datetime.now().isoformat(),
                "task_type": "summary",
                "original_goal": original_goal,
                "total_subtasks": total_subtasks,
                "session_id": session_id,
            },
        )

        # åˆ›å»ºDynamicActorå®ä¾‹
        actor = DynamicActor(
            actor_id=config.actor_id,
            task_id=config.task_id,
            task_description=task_spec.description,
            llm_client=self.llm,
            tools=tools,
            functions=functions,
            system_prompt=config.system_prompt,
            config=config,
        )

        return actor

    def _create_fallback_agent(
        self, task_spec: TaskSpecification, error_msg: str
    ) -> "DynamicActor":
        """åˆ›å»ºé™çº§æ™ºèƒ½ä½“."""

        # ä½¿ç”¨æœ€åŸºç¡€çš„é…ç½® - ä¼˜å…ˆä½¿ç”¨ web_researchï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ file_operations
        basic_tools = []

        # ä¼˜å…ˆå°è¯•ä½¿ç”¨ç½‘ç»œæœç´¢å·¥å…·
        if self.tool_bundles.get("web_research") and self.tool_bundles["web_research"].get("tools"):
            basic_tools = [self.tool_bundles["web_research"]["tools"][0]]
        # å¦‚æœæ²¡æœ‰ç½‘ç»œæœç´¢ï¼Œå°è¯•ä½¿ç”¨æ–‡ä»¶æ“ä½œå·¥å…·
        elif self.tool_bundles.get("file_operations") and self.tool_bundles["file_operations"].get(
            "tools"
        ):
            basic_tools = [self.tool_bundles["file_operations"]["tools"][0]]
        # å¦‚æœæ‰€æœ‰å·¥å…·éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨ä»»ä½•å¯ç”¨çš„ç¬¬ä¸€ä¸ªå·¥å…·
        else:
            for _bundle_name, bundle_data in self.tool_bundles.items():
                if bundle_data.get("tools"):
                    basic_tools = [bundle_data["tools"][0]]
                    break

        # å¦‚æœå®Œå…¨æ²¡æœ‰å·¥å…·ï¼Œåˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼ˆå…è®¸æ— å·¥å…·è¿è¡Œï¼‰
        if not basic_tools:
            logger.warning("No tools available for fallback agent, creating agent without tools")

        basic_functions = self._tools_to_functions(basic_tools)

        fallback_config = ActorConfiguration(
            actor_id=f"fallback_{uuid.uuid4().hex[:8]}",
            task_id=task_spec.task_id,
            persona="æ‚¨å¥½ï¼æˆ‘æ˜¯åŸºç¡€æ™ºèƒ½åŠ©æ‰‹ï¼Œä¼šå°½åŠ›å®Œæˆä»»åŠ¡ã€‚",
            tools=[tool.name for tool in basic_tools],
            knowledge="åŸºç¡€å·¥ä½œåŸåˆ™ï¼šç†è§£éœ€æ±‚ã€å°è¯•è§£å†³ã€åŠæ—¶åé¦ˆã€‚",
            system_prompt="æ‚¨æ˜¯ä¸€ä¸ªåŸºç¡€æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·ä½¿ç”¨å¯ç”¨å·¥å…·å°½åŠ›å®Œæˆç”¨æˆ·çš„ä»»åŠ¡ã€‚",
            execution_config={"max_iterations": 5, "timeout": 60},
            metadata={"fallback_reason": error_msg, "created_at": datetime.now().isoformat()},
        )

        # TODO: å®ç° DynamicActor åæ›¿æ¢
        from .dynamic_actor import DynamicActor

        return DynamicActor(
            actor_id=fallback_config.actor_id,
            task_id=fallback_config.task_id,
            task_description=task_spec.description,
            llm_client=self.llm,
            tools=basic_tools,
            functions=basic_functions,
            system_prompt=fallback_config.system_prompt,
            config=fallback_config,
        )
