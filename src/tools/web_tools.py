"""ç½‘ç»œæœç´¢å’Œä¿¡æ¯è·å–å·¥å…·ã€‚"""

import json
import os
import time
from typing import Any, Dict, List, Optional

import requests
from langchain_tavily import TavilySearch

from .base import BaseTool, ToolError


class WebSearchTool(BaseTool):
    """ç½‘ç»œæœç´¢å·¥å…·ï¼ŒåŸºäº Tavily Search å®ç°ã€‚"""
    
    def __init__(
        self, 
        api_key: Optional[str] = None,
        max_results: int = 5,
        search_depth: str = "advanced",
        include_answer: bool = True,
        include_raw_content: bool = False
    ):
        super().__init__(
            name="web_search",
            description="ä½¿ç”¨ AI ä¼˜åŒ–çš„æœç´¢å¼•æ“è¿›è¡Œç½‘ç»œä¿¡æ¯æœç´¢",
            required_permissions=["internet_access"],
            max_results=max_results,
            search_depth=search_depth,
            include_answer=include_answer,
            include_raw_content=include_raw_content
        )
        
        # è·å– API Key
        self.api_key = api_key or os.getenv("TAVILY_API_KEY")
        if not self.api_key:
            raise ToolError("Tavily API key is required. Set TAVILY_API_KEY environment variable or pass api_key parameter.")
        
        # åˆå§‹åŒ– Tavily æœç´¢
        try:
            self.tavily = TavilySearch(
                tavily_api_key=self.api_key,
                max_results=max_results,
                search_depth=search_depth,
                include_answer=include_answer,
                include_raw_content=include_raw_content,
            )
        except Exception as e:
            raise ToolError(f"Failed to initialize Tavily Search: {str(e)}")
    
    async def execute(self, query: str, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œç½‘ç»œæœç´¢ã€‚
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            **kwargs: é¢å¤–çš„æœç´¢å‚æ•°
            
        Returns:
            æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - query: æœç´¢æŸ¥è¯¢
            - answer: AI ç”Ÿæˆçš„ç­”æ¡ˆæ‘˜è¦
            - results: è¯¦ç»†æœç´¢ç»“æœåˆ—è¡¨
            - response_time: å“åº”æ—¶é—´
            
        Raises:
            ToolError: æœç´¢å¤±è´¥
        """
        if not query or not query.strip():
            raise ToolError("Search query cannot be empty")
        
        try:
            # æ‰§è¡Œæœç´¢
            result = self.tavily.run(query)
            
            # ç¡®ä¿ç»“æœæ˜¯å­—å…¸æ ¼å¼
            if isinstance(result, str):
                try:
                    result = json.loads(result)
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯ JSONï¼ŒåŒ…è£…æˆå­—å…¸
                    result = {
                        "query": query,
                        "answer": result,
                        "results": [],
                        "response_time": 0
                    }
            
            # éªŒè¯å’Œæ ‡å‡†åŒ–ç»“æœæ ¼å¼
            if not isinstance(result, dict):
                raise ToolError(f"Unexpected result format: {type(result)}")
            
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            standardized_result = {
                "query": result.get("query", query),
                "answer": result.get("answer", ""),
                "results": result.get("results", []),
                "response_time": result.get("response_time", 0),
                "images": result.get("images", []),
                "follow_up_questions": result.get("follow_up_questions"),
                "request_id": result.get("request_id")
            }
            
            return standardized_result
            
        except Exception as e:
            raise ToolError(f"Web search failed for query '{query}': {str(e)}")
    
    def execute_sync(self, query: str, **kwargs) -> Dict[str, Any]:
        """åŒæ­¥ç‰ˆæœ¬çš„ç½‘ç»œæœç´¢ã€‚"""
        import asyncio
        return asyncio.run(self.execute(query, **kwargs))
    
    def format_results(self, results: Dict[str, Any], max_length: int = 1000) -> str:
        """
        æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºå¯è¯»å­—ç¬¦ä¸²ã€‚
        
        Args:
            results: æœç´¢ç»“æœå­—å…¸
            max_length: æœ€å¤§é•¿åº¦é™åˆ¶
            
        Returns:
            æ ¼å¼åŒ–çš„æœç´¢ç»“æœå­—ç¬¦ä¸²
        """
        formatted = []
        
        # æ·»åŠ æŸ¥è¯¢å’Œç­”æ¡ˆ
        formatted.append(f"ğŸ” æŸ¥è¯¢: {results.get('query', '')}")
        
        if results.get('answer'):
            answer = results['answer']
            if len(answer) > max_length // 2:
                answer = answer[:max_length//2] + "..."
            formatted.append(f"ğŸ’¡ ç­”æ¡ˆæ‘˜è¦: {answer}")
        
        # æ·»åŠ æœç´¢ç»“æœ
        search_results = results.get('results', [])
        if search_results:
            formatted.append(f"\nğŸ“‹ æœç´¢ç»“æœ ({len(search_results)} æ¡):")
            
            for i, result in enumerate(search_results[:3], 1):  # åªæ˜¾ç¤ºå‰3æ¡
                title = result.get('title', 'æ— æ ‡é¢˜')
                url = result.get('url', '')
                content = result.get('content', '')
                
                # æˆªæ–­å†…å®¹
                if content and len(content) > 150:
                    content = content[:150] + "..."
                
                formatted.append(f"\n{i}. {title}")
                if url:
                    formatted.append(f"   ğŸ”— {url}")
                if content:
                    formatted.append(f"   ğŸ“„ {content}")
        
        # æ·»åŠ å“åº”æ—¶é—´
        if results.get('response_time'):
            formatted.append(f"\nâ±ï¸ å“åº”æ—¶é—´: {results['response_time']:.2f}ç§’")
        
        result_text = "\n".join(formatted)
        
        # ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
        if len(result_text) > max_length:
            result_text = result_text[:max_length] + "...\n[ç»“æœå·²æˆªæ–­]"
        
        return result_text


class BraveSearchTool(BaseTool):
    """åŸºäº Brave Search API çš„ç½‘ç»œæœç´¢å·¥å…·ã€‚"""
    
    def __init__(
        self, 
        api_key: Optional[str] = None,
        max_results: int = 3,
        country: str = "US",
        search_lang: str = "en",
        ui_lang: str = "en-US",
        safe_search: str = "moderate",
        freshness: Optional[str] = None,
        text_decorations: bool = True,
        spellcheck: bool = True
    ):
        super().__init__(
            name="brave_search",
            description="ä½¿ç”¨ Brave Search API è¿›è¡Œç½‘ç»œä¿¡æ¯æœç´¢",
            required_permissions=["internet_access"],
            max_results=max_results,
            country=country,
            search_lang=search_lang,
            ui_lang=ui_lang,
            safe_search=safe_search,
            freshness=freshness,
            text_decorations=text_decorations,
            spellcheck=spellcheck
        )
        
        # è·å– API Key
        self.api_key = api_key or os.getenv("BRAVE_SEARCH_API_KEY")
        if not self.api_key:
            raise ToolError("Brave Search API key is required. Set BRAVE_SEARCH_API_KEY environment variable or pass api_key parameter.")
        
        # API é…ç½®
        self.base_url = "https://api.search.brave.com/res/v1/web/search"
        self.headers = {
            "Accept": "application/json",
            "Accept-Encoding": "gzip",
            "X-Subscription-Token": self.api_key
        }
        
        # æœç´¢å‚æ•°
        self.max_results = max_results
        self.country = country
        self.search_lang = search_lang
        self.ui_lang = ui_lang
        self.safe_search = safe_search
        self.freshness = freshness
        self.text_decorations = text_decorations
        self.spellcheck = spellcheck
    
    async def execute(self, query: str, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œç½‘ç»œæœç´¢ã€‚
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            **kwargs: é¢å¤–çš„æœç´¢å‚æ•°ï¼Œå¯ä»¥è¦†ç›–é»˜è®¤é…ç½®
            
        Returns:
            æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - query: æœç´¢æŸ¥è¯¢
            - web: ç½‘é¡µæœç´¢ç»“æœ
            - infobox: ä¿¡æ¯æ¡†ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            - news: æ–°é—»ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            - videos: è§†é¢‘ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            - locations: ä½ç½®ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            - response_time: å“åº”æ—¶é—´
            
        Raises:
            ToolError: æœç´¢å¤±è´¥
        """
        if not query or not query.strip():
            raise ToolError("Search query cannot be empty")
        
        # æ„å»ºæœç´¢å‚æ•°
        params = {
            "q": query.strip(),
            "count": kwargs.get("count", self.max_results),
            "offset": kwargs.get("offset", 0),
            "country": kwargs.get("country", self.country),
            "search_lang": kwargs.get("search_lang", self.search_lang),
            "ui_lang": kwargs.get("ui_lang", self.ui_lang),
            "safesearch": kwargs.get("safe_search", self.safe_search),
            "text_decorations": kwargs.get("text_decorations", self.text_decorations),
            "spellcheck": kwargs.get("spellcheck", self.spellcheck)
        }
        
        # æ·»åŠ å¯é€‰å‚æ•°
        if self.freshness or kwargs.get("freshness"):
            params["freshness"] = kwargs.get("freshness", self.freshness)
        
        try:
            start_time = time.time()
            
            # å‘é€æœç´¢è¯·æ±‚
            response = requests.get(
                self.base_url,
                headers=self.headers,
                params=params,
                timeout=30
            )
            
            response_time = time.time() - start_time
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code == 429:
                raise ToolError("Rate limit exceeded. Please try again later.")
            elif response.status_code == 401:
                raise ToolError("Invalid API key or unauthorized access.")
            elif response.status_code != 200:
                raise ToolError(f"Brave Search API error: {response.status_code} - {response.text}")
            
            # è§£æå“åº”
            result = response.json()
            
            # æ ‡å‡†åŒ–ç»“æœæ ¼å¼
            standardized_result = {
                "query": query,
                "web": result.get("web", {}),
                "infobox": result.get("infobox"),
                "news": result.get("news"),
                "videos": result.get("videos"),
                "locations": result.get("locations"),
                "response_time": response_time,
                "total_results": result.get("web", {}).get("total", 0)
            }
            
            return standardized_result
            
        except requests.RequestException as e:
            raise ToolError(f"Network error during Brave search for query '{query}': {str(e)}")
        except json.JSONDecodeError as e:
            raise ToolError(f"Failed to parse Brave search response: {str(e)}")
        except Exception as e:
            raise ToolError(f"Brave search failed for query '{query}': {str(e)}")
    
    def execute_sync(self, query: str, **kwargs) -> Dict[str, Any]:
        """åŒæ­¥ç‰ˆæœ¬çš„ç½‘ç»œæœç´¢ã€‚"""
        import asyncio
        try:
            # å°è¯•è·å–å½“å‰äº‹ä»¶å¾ªç¯
            loop = asyncio.get_running_loop()
            # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œåˆ›å»ºæ–°ä»»åŠ¡
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, self.execute(query, **kwargs))
                return future.result()
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ asyncio.run
            return asyncio.run(self.execute(query, **kwargs))
    
    def format_results(self, results: Dict[str, Any], max_length: int = 1000) -> str:
        """
        æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºå¯è¯»å­—ç¬¦ä¸²ã€‚
        
        Args:
            results: æœç´¢ç»“æœå­—å…¸
            max_length: æœ€å¤§é•¿åº¦é™åˆ¶
            
        Returns:
            æ ¼å¼åŒ–çš„æœç´¢ç»“æœå­—ç¬¦ä¸²
        """
        formatted = []
        
        # æ·»åŠ æŸ¥è¯¢ä¿¡æ¯
        formatted.append(f"ğŸ” æŸ¥è¯¢: {results.get('query', '')}")
        
        # æ·»åŠ æ€»ç»“æœæ•°
        total_results = results.get('total_results', 0)
        if total_results > 0:
            formatted.append(f"ğŸ“Š æ‰¾åˆ°çº¦ {total_results:,} æ¡ç»“æœ")
        
        # æ·»åŠ ä¿¡æ¯æ¡†ï¼ˆå¦‚æœæœ‰ï¼‰
        infobox = results.get('infobox')
        if infobox:
            formatted.append(f"\nğŸ“‹ ä¿¡æ¯æ¡†:")
            if infobox.get('title'):
                formatted.append(f"   æ ‡é¢˜: {infobox['title']}")
            if infobox.get('description'):
                desc = infobox['description']
                if len(desc) > 200:
                    desc = desc[:200] + "..."
                formatted.append(f"   æè¿°: {desc}")
        
        # æ·»åŠ ç½‘é¡µæœç´¢ç»“æœ
        web_results = results.get('web', {}).get('results', [])
        if web_results:
            formatted.append(f"\nğŸŒ ç½‘é¡µç»“æœ:")
            
            for i, result in enumerate(web_results[:3], 1):  # æ˜¾ç¤ºå‰3æ¡
                title = result.get('title', 'æ— æ ‡é¢˜')
                url = result.get('url', '')
                description = result.get('description', '')
                
                # æˆªæ–­æè¿°
                if description and len(description) > 150:
                    description = description[:150] + "..."
                
                formatted.append(f"\n{i}. {title}")
                if url:
                    formatted.append(f"   ğŸ”— {url}")
                if description:
                    formatted.append(f"   ğŸ“„ {description}")
        
        # æ·»åŠ æ–°é—»ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        news_data = results.get('news')
        if news_data and isinstance(news_data, dict):
            news_results = news_data.get('results', [])
            if news_results:
                formatted.append(f"\nğŸ“° æ–°é—»ç»“æœ:")
                for i, news in enumerate(news_results[:3], 1):  # æ˜¾ç¤ºå‰3æ¡æ–°é—»
                    title = news.get('title', 'æ— æ ‡é¢˜')
                    url = news.get('url', '')
                    age = news.get('age', '')
                    
                    formatted.append(f"\n{i}. {title}")
                    if url:
                        formatted.append(f"   ğŸ”— {url}")
                    if age:
                        formatted.append(f"   ğŸ“… {age}")
        
        # æ·»åŠ å“åº”æ—¶é—´
        if results.get('response_time'):
            formatted.append(f"\nâ±ï¸ å“åº”æ—¶é—´: {results['response_time']:.2f}ç§’")
        
        result_text = "\n".join(formatted)
        
        # ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§é•¿åº¦
        if len(result_text) > max_length:
            result_text = result_text[:max_length] + "...\n[ç»“æœå·²æˆªæ–­]"
        
        return result_text


class WebContentExtractorTool(BaseTool):
    """ç½‘é¡µå†…å®¹æå–å·¥å…·ã€‚"""
    
    def __init__(self):
        super().__init__(
            name="extract_web_content",
            description="ä»æŒ‡å®šURLæå–ç½‘é¡µå†…å®¹",
            required_permissions=["internet_access"]
        )
    
    async def execute(self, url: str, max_length: int = 5000) -> str:
        """
        æå–ç½‘é¡µå†…å®¹ã€‚
        
        Args:
            url: ç½‘é¡µURL
            max_length: æœ€å¤§å†…å®¹é•¿åº¦
            
        Returns:
            æå–çš„ç½‘é¡µå†…å®¹
            
        Raises:
            ToolError: å†…å®¹æå–å¤±è´¥
        """
        if not url or not url.strip():
            raise ToolError("URL cannot be empty")
        
        try:
            import requests
            from bs4 import BeautifulSoup
            
            # å‘é€HTTPè¯·æ±‚
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            # è§£æHTML
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼å…ƒç´ 
            for script in soup(["script", "style"]):
                script.decompose()
            
            # æå–æ–‡æœ¬å†…å®¹
            text = soup.get_text()
            
            # æ¸…ç†æ–‡æœ¬
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk)
            
            # é™åˆ¶é•¿åº¦
            if len(text) > max_length:
                text = text[:max_length] + "...[å†…å®¹å·²æˆªæ–­]"
            
            return text
            
        except requests.RequestException as e:
            raise ToolError(f"Failed to fetch URL {url}: {str(e)}")
        except Exception as e:
            raise ToolError(f"Failed to extract content from {url}: {str(e)}")
    
    def execute_sync(self, url: str, max_length: int = 5000) -> str:
        """åŒæ­¥ç‰ˆæœ¬çš„ç½‘é¡µå†…å®¹æå–ã€‚"""
        import asyncio
        return asyncio.run(self.execute(url, max_length))


# å¯¼å‡ºçš„ç±»
__all__ = [
    "WebSearchTool",
    "BraveSearchTool", 
    "WebContentExtractorTool"
]
